{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5537538,"sourceType":"datasetVersion","datasetId":3191565}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport wandb\nimport torch\nimport random\nimport argparse\nimport pandas as pd\nimport torch.nn as nn\nimport torch.optim as optim\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\n### Create an argument parser object\n# parser=argparse.ArgumentParser()\n\n### Define command-line arguments with descriptions, data types, default values, and choices where applicable\n### WandB project name\n# parser.add_argument('-wp',      '--wandb_project',      help='project name',                                                    type=str,       default='CS6910_A3_')\n\n### WandB entity name\n# parser.add_argument('-we',      '--wandb_entity',       help='entity name',                                                     type=str,       default='cs22m064'  )\n\n### Number of Epochs\n# parser.add_argument('-e',       '--epochs',             help='epochs',                          choices=[5,10],                 type=int,       default=5           )\n\n### Batch Size\n# parser.add_argument('-b',       '--batch_size',         help='batch sizes',                     choices=[32,64,128],            type=int,       default=32          )\n\n### Optimizer Choice\n# parser.add_argument('-o',       '--optimizer',          help='optimizer',                       choices=['adam','nadam'],       type=str,       default='adam'      )\n\n### Learning Rate\n# parser.add_argument('-lr',      '--learning_rate',      help='learning rates',                  choices=[1e-2,1e-3],            type=float,     default=1e-2        )\n\n### Number Of layers in Encoder\n# parser.add_argument('-nle',     '--num_layers_en',      help='number of layers in encoder',     choices=[1,2,3],                type=int,       default=2           )\n\n### Number of layers in Decoder\n# parser.add_argument('-nld',     '--num_layers_dec',     help='number of layers in decoder',     choices=[1,2,3],                type=int,       default=2           )\n# parser.add_argument('-sz',      '--hidden_size',        help='hidden layer size',               choices=[16,32,64,256],         type=int,       default=256         )\n\n### Add Input Language\n# parser.add_argument('-il',      '--input_lang',         help='input language',                  choices=['hin','tel'],          type=str,       default='hin'       )\n\n### Add target Language\n# parser.add_argument('-tl',      '--target_lang',        help='target language',                 choices=['hin','tel'],          type=str,       default='hin'       )\n\n### Select Cell Type :LSTM , GRU, RNN\n# parser.add_argument('-ct',      '--cell_type',          help='cell type',                       choices=['LSTM','GRU','RNN'],   type=str,       default='LSTM'      )\n\n### Select Drop out value\n# parser.add_argument('-do',      '--drop_out',           help='drop out',                        choices=[0.0,0.2,0.3],          type=float,     default='0.2'       )\n\n### Select Embedding size\n# parser.add_argument('-es',      '--embedding_size',     help='embedding size',                  choices=[16,32,64,256],         type=int,       default=256         )\n\n### Bidirectional true or false\n# parser.add_argument('-bd',      '--bidirectional',      help='bidirectional',                   choices=[True,False],           type=bool,      default=False       )\n\n### Attention True or False\n# parser.add_argument('-at',      '--attention',          help='attention',                       choices=[True,False],           type=bool,      default=True        )\n\n# args=parser.parse_args()\n\nproject_name_ap     = 'Assifnment_3'\nentity_name_ap      = 'samruddhipatil2526'\n# epochs_ap           = args.epochs\n# batch_size_ap       = args.batch_size\n# optimizer_ap        = args.optimizer\n# learning_rate_ap    = args.learning_rate\n# num_layers_en_ap    = args.num_layers_en\n# num_layers_dec_ap   = args.num_layers_dec\n# hidden_size_ap      = args.hidden_size\ninput_lang_ap       = 'eng'\ntarget_lang_ap      = 'hin'\n# cell_type_ap        = args.cell_type\n# drop_out_ap         = args.drop_out\n# embedding_size_ap   = args.embedding_size\n# bidirectional_ap    = args.bidirectional\nattention_ap        = False\n\n#dir = '/kaggle/input/aksharantar/aksharantar_sampled'\n### Define the directory path where the data is located\ndir = '/kaggle/working/aksharantar_sampled'\n\n### Check if CUDA is available for GPU acceleration\nuse_cuda = torch.cuda.is_available()\n\n# Define special tokens for the vocabulary\n### Start-of-sequence token\nSOS_token = 0\n### End-of-sequence token\nEOS_token = 1\n### Unknown token\nUNK_token = 3\n### Padding token\nPAD_token = 4\n\n\n### # Define the sweep configuration using Bayesian optimization method\nsweep_config ={\n    'method':'bayes'\n}\n\nmetric = {\n    'name' : 'validation_accuracy',\n    'goal' : 'maximize'\n}\nsweep_config['metric'] = metric\n\nparameters_dict={\n    'epochs':{\n        'values' : [10]\n    },\n    'hidden_size':{\n        'values' : [128,256,512]\n    },\n    'cell_type':{\n        'values' : ['LSTM','RNN','GRU']\n    },\n    'learning_rate':{\n        'values' : [1e-2,1e-3]\n    },\n    'num_layers_en':{\n        'values' : [1,2,3]\n    },\n    'num_layers_dec':{\n        'values' : [1,2,3]\n    },\n    'drop_out':{\n        'values' : [0.0,0.2,0.3]\n    },\n    'embedding_size':{\n        'values' : [64,128,256,512]\n    },\n    'batch_size':{\n        'values' : [32,64,128]\n    },\n    'optimizer':{\n        'values' : ['adam','nadam']\n    },\n    'bidirectional':{\n        'values' : [True,False]\n    }\n}\nsweep_config['parameters'] = parameters_dict\n\nsweep_id = wandb.sweep(sweep_config, project=project_name_ap)\n\nclass Vocabulary:\n\n    def __init__(self, name):\n        self.char2count = {}\n        self.char2index = {}\n        self.n_chars = 4\n        self.index2char = {0: '<', 1: '>',2 : '?', 3:'.'}\n        self.name = name\n\n    def addWord(self, word):\n        for char in word:\n            if char not in self.char2index:\n                self.char2index[char] = self.n_chars\n                self.index2char[self.n_chars] = char\n                self.char2count[char] = 1\n                self.n_chars += 1\n            else:\n                self.char2count[char] += 1\n        \n\ndef prepareData(dir, lang1, lang2):\n\n    data = pd.read_csv(dir,sep=\",\",names=['input', 'target'])\n    max_input_length = max([len(txt) for txt in data['input'].to_list()])\n    max_target_length = max([len(txt) for txt in data['target'].to_list()])\n\n    input_lang = Vocabulary(lang1)\n    output_lang = Vocabulary(lang2)\n\n    pairs = []\n    input_list,target_list = data['input'].to_list(),data['target'].to_list()\n    for i in range(len(input_list)):\n        pairs.append([input_list[i],target_list[i]])\n\n    for pair in pairs:\n        input_lang.addWord(pair[0])\n        output_lang.addWord(pair[1])\n\n    prepared_data = {\n        'input_lang' : input_lang,\n        'output_lang' : output_lang,\n        'pairs' : pairs,\n        'max_input_length' : max_input_length,\n        'max_target_length' : max_target_length\n    }\n\n    return prepared_data\n\nclass EncoderRNN(nn.Module):\n    def __init__(self, input_size, configuration):\n        \"\"\"\n        Initialize the EncoderRNN module.\n\n        Args:\n            input_size (int): Size of the input vocabulary.\n            configuration (dict): Configuration dictionary containing model parameters.\n\n        Configuration Parameters:\n            - embedding_size (int): Size of the embedding layer.\n            - hidden_size (int): Size of the hidden state.\n            - num_layers_encoder (int): Number of layers in the encoder.\n            - cell_type (str): Type of RNN cell ('RNN', 'GRU', or 'LSTM').\n            - drop_out (float): Dropout rate.\n            - bi_directional (bool): Whether the encoder is bidirectional.\n        \"\"\"\n        super(EncoderRNN, self).__init__()\n\n        self.embedding_size = configuration['embedding_size']\n        self.hidden_size = configuration['hidden_size']\n        self.num_layers_encoder = configuration[\"num_layers_encoder\"]\n        self.cell_type = configuration[\"cell_type\"]\n        self.drop_out = configuration['drop_out']\n        self.bi_directional = configuration['bi_directional']\n\n        self.embedding = nn.Embedding(input_size, self.embedding_size)\n        self.dropout = nn.Dropout(self.drop_out)\n        self.cell_layer = None\n        if self.cell_type == 'RNN':\n            self.cell_layer = nn.RNN(self.embedding_size, self.hidden_size, num_layers = self.num_layers_encoder, dropout = self.drop_out, bidirectional = self.bi_directional)\n        elif self.cell_type == 'GRU':\n            self.cell_layer = nn.GRU(self.embedding_size, self.hidden_size, num_layers = self.num_layers_encoder, dropout = self.drop_out, bidirectional = self.bi_directional)\n        elif self.cell_type == 'LSTM':\n            self.cell_layer = nn.LSTM(self.embedding_size, self.hidden_size, num_layers = self.num_layers_encoder, dropout = self.drop_out, bidirectional = self.bi_directional)\n \n    def forward(self, input, batch_size, hidden):\n        \"\"\"\n        Forward pass of the EncoderRNN.\n\n        Args:\n            input (Tensor): Input tensor containing indices of input sequence.\n            batch_size (int): Size of the input batch.\n            hidden (Tensor): Initial hidden state.\n\n        Returns:\n            output (Tensor): Output tensor from the RNN layer.\n            hidden (Tensor): Hidden state tensor.\n        \"\"\"\n        embedded = self.dropout(self.embedding(input).view(1,batch_size, -1))\n        output = embedded\n        output, hidden = self.cell_layer(output, hidden)\n        return output, hidden\n\n    def initHidden(self ,batch_size, num_layers_enc):\n        \"\"\"\n        Initialize the hidden state tensor.\n\n        Args:\n            batch_size (int): Size of the input batch.\n            num_layers_enc (int): Number of layers in the encoder.\n\n        Returns:\n            Tensor: Initialized hidden state tensor.\n        \"\"\"\n        res = None\n        if self.bi_directional:\n            res = torch.zeros(num_layers_enc* 2, batch_size, self.hidden_size)\n        else:\n            res = torch.zeros(num_layers_enc, batch_size, self.hidden_size)\n        if use_cuda : \n            return res.cuda()\n        else :\n            return res\n\nclass DecoderRNN(nn.Module):\n    def __init__(self, configuration,  output_size):\n        super(DecoderRNN, self).__init__()\n        \"\"\"\n        Initialize the DecoderRNN module.\n\n        Args:\n            configuration (dict): Configuration dictionary containing model parameters.\n            output_size (int): Size of the output vocabulary.\n        \n        Configuration Parameters:\n            - embedding_size (int): Size of the embedding layer.\n            - hidden_size (int): Size of the hidden state.\n            - num_layers_decoder (int): Number of layers in the decoder.\n            - cell_type (str): Type of RNN cell ('RNN', 'GRU', or 'LSTM').\n            - drop_out (float): Dropout rate.\n            - bi_directional (bool): Whether the decoder is bidirectional.\n        \"\"\"\n        self.embedding_size = configuration['embedding_size']\n        self.hidden_size = configuration['hidden_size']\n        self.num_layers_decoder = configuration[\"num_layers_decoder\"]\n        self.cell_type = configuration[\"cell_type\"]\n        self.drop_out = configuration[\"drop_out\"]\n        self.bi_directional = configuration[\"bi_directional\"]\n        self.dropout = nn.Dropout(self.drop_out)\n        \n        self.embedding = nn.Embedding(output_size, self.embedding_size)\n\n        self.cell_layer = None\n        if self.cell_type == 'RNN':\n            self.cell_layer = nn.RNN(self.embedding_size, self.hidden_size, num_layers = self.num_layers_decoder, dropout = self.drop_out, bidirectional = self.bi_directional)\n        elif self.cell_type == 'GRU':\n            self.cell_layer =   nn.GRU(self.embedding_size, self.hidden_size, num_layers = self.num_layers_decoder, dropout = self.drop_out, bidirectional = self.bi_directional)\n        elif self.cell_type == 'LSTM':\n            self.cell_layer = nn.LSTM(self.embedding_size, self.hidden_size, num_layers = self.num_layers_decoder, dropout = self.drop_out, bidirectional = self.bi_directional)\n        \n        if self.bi_directional:\n            self.out = nn.Linear(self.hidden_size * 2 ,output_size)\n        else:\n            self.out = nn.Linear(self.hidden_size, output_size)\n        \n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, batch_size, hidden):\n        \n        output = self.dropout(self.embedding(input).view(1,batch_size, -1))\n        output = F.relu(output)\n        output, hidden = self.cell_layer(output, hidden)\n        \n        output = self.softmax(self.out(output[0]))\n        return output, hidden\n\ndef indexesFromWord(lang, word):\n    \"\"\"\n    Convert a word into a list of indices based on the character-to-index mapping of the language.\n\n    Args:\n        lang (Lang): Language object containing the character-to-index mapping.\n        word (str): Input word to convert into indices.\n\n    Returns:\n        index_list (list): List of indices corresponding to the characters in the word.\n    \"\"\"\n    index_list = []\n    for char in word:\n        if char in lang.char2index.keys():\n            index_list.append(lang.char2index[char])\n        else:\n            index_list.append(UNK_token)\n    return index_list\n\ndef variableFromSentence(lang, word, max_length):\n    \"\"\"\n    Convert a word into a PyTorch tensor variable.\n\n    Args:\n        lang (Lang): Language object.\n        word (str): Input word to convert.\n        max_length (int): Maximum length of the sequence.\n\n    Returns:\n        result (Tensor): PyTorch tensor variable representing the input word.\n    \"\"\"\n    indexes = indexesFromWord(lang, word)\n    indexes.append(EOS_token)\n    indexes.extend([PAD_token] * (max_length - len(indexes)))\n    result = torch.LongTensor(indexes)\n    if use_cuda:\n        return result.cuda()\n    else:\n        return result\n\ndef variablesFromPairs(input_lang, output_lang, pairs, max_length):\n    \"\"\"\n    Convert a list of word pairs into PyTorch tensor variables.\n\n    Args:\n        input_lang (Lang): Language object for the input language.\n        output_lang (Lang): Language object for the output language.\n        pairs (list): List of word pairs.\n        max_length (int): Maximum length of the sequence.\n\n    Returns:\n        res (list): List of tuples containing input and target tensor variables.\n    \"\"\"\n    res = []\n    for pair in pairs:\n        input_variable = variableFromSentence(input_lang, pair[0], max_length)\n        target_variable = variableFromSentence(output_lang, pair[1], max_length)\n        res.append((input_variable, target_variable))\n    return res\n\ndef train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, configuration, max_length, teacher_forcing_ratio = 0.5):\n    \n    batch_size = configuration['batch_size']\n    num_layers_enc = configuration['num_layers_encoder']\n    encoder_hidden = encoder.initHidden(batch_size,num_layers_enc)\n\n    input_tensor = Variable(input_tensor.transpose(0, 1))\n    target_tensor = Variable(target_tensor.transpose(0, 1))\n\n    if configuration[\"cell_type\"] == \"LSTM\":\n        encoder_cell_state = encoder.initHidden(batch_size,num_layers_enc)\n        encoder_hidden = (encoder_hidden, encoder_cell_state)\n\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n\n    loss = 0\n\n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(input_tensor[ei], batch_size, encoder_hidden)\n\n    decoder_input = Variable(torch.LongTensor([SOS_token]*batch_size))\n    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n\n    decoder_hidden = encoder_hidden\n\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    if use_teacher_forcing:\n        for di in range(target_length):\n            decoder_output, decoder_hidden= decoder(decoder_input, batch_size, decoder_hidden)\n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di]\n\n    else:\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(decoder_input, batch_size,decoder_hidden)\n            topv, topi = decoder_output.data.topk(1)\n            decoder_input = torch.cat(tuple(topi))\n\n            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n\n            loss += criterion(decoder_output, target_tensor[di])\n\n    loss.backward()\n\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n\n    return loss.item() / target_length\n  \ndef cal_val_loss(encoder, decoder, input_tensor, target_tensor, configuration, criterion , max_length):\n\n    with torch.no_grad():\n\n        batch_size = configuration['batch_size']\n        num_layers_enc = configuration['num_layers_encoder']\n        encoder_hidden = encoder.initHidden(batch_size,num_layers_enc)\n\n        input_tensor = Variable(input_tensor.transpose(0, 1))\n        target_tensor = Variable(target_tensor.transpose(0, 1))\n            \n        if configuration[\"cell_type\"] == \"LSTM\":\n            encoder_cell_state = encoder.initHidden(batch_size,num_layers_enc)\n            encoder_hidden = (encoder_hidden, encoder_cell_state)\n\n        input_length = input_tensor.size()[0]\n        target_length = target_tensor.size()[0]\n\n        loss = 0\n            \n        for ei in range(input_length):\n            encoder_output, encoder_hidden = encoder(input_tensor[ei], batch_size, encoder_hidden)\n\n        decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size))\n        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n\n        decoder_hidden = encoder_hidden\n\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(decoder_input, batch_size, decoder_hidden)\n            topv, topi = decoder_output.data.topk(1)\n            decoder_input = torch.cat(tuple(topi))\n\n            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n            loss += criterion(decoder_output, target_tensor[di])\n\n    return loss.item() / target_length\n\ndef evaluate(encoder, decoder, loader, configuration, criterion , max_length):\n\n    with torch.no_grad():\n\n        batch_size = configuration['batch_size']\n        total = 0\n        correct = 0\n        \n        for batch_x, batch_y in loader:\n            num_layers_enc = configuration['num_layers_encoder']\n            encoder_hidden = encoder.initHidden(batch_size,num_layers_enc)\n\n            input_variable = Variable(batch_x.transpose(0, 1))\n            target_variable = Variable(batch_y.transpose(0, 1))\n            \n            if configuration[\"cell_type\"] == \"LSTM\":\n                encoder_cell_state = encoder.initHidden(batch_size,num_layers_enc)\n                encoder_hidden = (encoder_hidden, encoder_cell_state)\n\n            input_length = input_variable.size()[0]\n            target_length = target_variable.size()[0]\n\n            output = torch.LongTensor(target_length, batch_size)\n\n            encoder_outputs = Variable(torch.zeros(max_length, batch_size, encoder.hidden_size))\n            encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n            \n            for ei in range(input_length):\n                encoder_output, encoder_hidden = encoder(input_variable[ei], batch_size, encoder_hidden)\n\n            decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size))\n            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n\n            decoder_hidden = encoder_hidden\n\n            for di in range(target_length):\n                decoder_output, decoder_hidden = decoder(decoder_input, batch_size, decoder_hidden)\n                topv, topi = decoder_output.data.topk(1)\n                decoder_input = torch.cat(tuple(topi))\n                output[di] = torch.cat(tuple(topi))\n\n            output = output.transpose(0,1)\n            for di in range(output.size()[0]):\n                ignore = [SOS_token, EOS_token, PAD_token]\n                sent = [configuration['output_lang'].index2char[letter.item()] for letter in output[di] if letter not in ignore]\n                y = [configuration['output_lang'].index2char[letter.item()] for letter in batch_y[di] if letter not in ignore]\n                if sent == y:\n                    correct += 1\n                total += 1\n\n    return (correct/total)*100\n\ndef trainIters(encoder, decoder, train_loader, val_loader, test_loader, learning_rate, configuration, wandb_flag):\n\n    max_length = configuration['max_length_word']\n\n    encoder_optimizer, decoder_optimizer = None, None\n\n    if configuration['optimizer']=='nadam':\n        encoder_optimizer = optim.NAdam(encoder.parameters(),lr=learning_rate)\n        decoder_optimizer = optim.NAdam(decoder.parameters(),lr=learning_rate)\n    else:\n        encoder_optimizer = optim.Adam(encoder.parameters(),lr=learning_rate)\n        decoder_optimizer = optim.Adam(decoder.parameters(),lr=learning_rate)\n\n    criterion = nn.NLLLoss()\n    \n    ep = configuration['epochs']\n\n    for i in range(ep):\n\n        train_loss_total = 0\n        val_loss_total = 0\n\n        for batchx, batchy in train_loader:\n            loss = None\n\n            if configuration['attention'] == False:\n                loss = train(batchx, batchy, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, configuration, max_length)\n            \n            train_loss_total += loss\n        \n        train_loss_total = train_loss_total/len(train_loader)\n        print('ep : ', i, ' | ', end='')\n        print('train loss :', train_loss_total, ' | ', end='')\n\n        for batchx, batchy in val_loader:\n            loss = None\n\n            if configuration['attention'] == False:\n                loss = cal_val_loss(encoder, decoder, batchx, batchy, configuration, criterion , max_length)\n            \n            val_loss_total += loss\n\n        val_loss_total = val_loss_total/len(val_loader)\n        # train_acc = evaluate(encoder, decoder, train_loader, configuration, criterion, max_length)\n        val_acc = evaluate(encoder, decoder, val_loader, configuration, criterion, max_length)\n        \n        # print(\"train accuracy : \" ,train_acc, ' | ', end='')\n        print('val loss :', val_loss_total, ' | ', end='')\n        print(\"val accuracy : \" ,val_acc)\n\n        if wandb_flag == True:\n            wandb.log({\n                \"train_loss\"           : train_loss_total,\n                \"validation_loss\"      : val_loss_total,\n                # \"train_accuracy\"       : train_acc,\n                \"validation_accuracy\"  : val_acc\n                })\n\n#     temp = configuration['batch_size']\n#     configuration['batch_size'] = 1\n#     print(\"test accuracy for the model : \" ,evaluate(encoder, decoder, test_loader, configuration, criterion, max_length))\n#     configuration['batch_size'] = temp\n\n\ndef main(config = None):\n\n    with wandb.init(config = config, entity = entity_name_ap) as run:\n        \n        config = wandb.config\n        run.name = 'hs_'+str(config.hidden_size)+'_bs_'+str(config.batch_size)+'_ct_'+config.cell_type+'_es_'+str(config.embedding_size)+'_do_'+str(config.drop_out)+'_nle_'+str(config.num_layers_en)+'_nld_'+str(config.num_layers_dec)+'_lr_'+str(config.learning_rate)+'_bd_'+str(config.bidirectional)\n\n        configuration = {\n\n                'hidden_size'         : config.hidden_size,\n                'source_lang'         : input_lang_ap,\n                'target_lang'         : target_lang_ap,\n                'cell_type'           : config.cell_type,\n                'num_layers_encoder'  : config.num_layers_en,\n                'num_layers_decoder'  : config.num_layers_en,\n                'drop_out'            : config.drop_out, \n                'embedding_size'      : config.embedding_size,\n                'bi_directional'      : config.bidirectional,\n                'batch_size'          : config.batch_size,\n                'attention'           : attention_ap,\n                'epochs'              : config.epochs,\n                'optimizer'           : config.optimizer\n\n            }\n        \n        \n        train_path = os.path.join(dir, configuration['target_lang'], configuration['target_lang'] + '_train.csv')\n        validation_path = os.path.join(dir, configuration['target_lang'], configuration['target_lang'] + '_valid.csv')\n        test_path = os.path.join(dir, configuration['target_lang'], configuration['target_lang'] + '_test.csv')\n\n        train_prepared_data= prepareData(train_path,configuration['source_lang'], configuration['target_lang'])\n\n        input_lang = train_prepared_data['input_lang']\n        output_lang = train_prepared_data['output_lang']\n        pairs = train_prepared_data['pairs']\n        max_input_length = train_prepared_data['max_input_length']\n        max_target_length = train_prepared_data['max_target_length']\n        \n        val_prepared_data= prepareData(validation_path,configuration['source_lang'], configuration['target_lang'])\n\n        val_pairs = val_prepared_data['pairs']\n        max_input_length_val = val_prepared_data['max_input_length']\n        max_target_length_val = val_prepared_data['max_target_length']\n\n        test_prepared_data= prepareData(validation_path, configuration['source_lang'], configuration['target_lang'])\n\n        test_pairs = test_prepared_data['pairs']\n        max_input_length_test = test_prepared_data['max_input_length']\n        max_target_length_test = test_prepared_data['max_target_length']\n\n        max_list = [max_input_length, max_target_length, max_input_length_val, max_target_length_val, max_input_length_test, max_target_length_test]\n        max_len_all = max(max_list)\n\n        max_len = max(max_input_length, max_target_length) + 2\n\n        configuration['input_lang'] = input_lang\n        configuration['output_lang'] = output_lang\n        configuration['max_length_word'] = max_len_all + 1\n\n        encoder1 = EncoderRNN(input_lang.n_chars, configuration)\n        decoder1 = DecoderRNN(configuration, output_lang.n_chars)\n        if use_cuda:\n            encoder1=encoder1.cuda()\n            decoder1=decoder1.cuda()\n\n        pairs = variablesFromPairs(configuration['input_lang'], configuration['output_lang'], pairs , configuration['max_length_word'])\n        val_pairs = variablesFromPairs(configuration['input_lang'], configuration['output_lang'], val_pairs, configuration['max_length_word'])\n        test_pairs = variablesFromPairs(configuration['input_lang'], configuration['output_lang'], test_pairs, configuration['max_length_word'])\n\n        train_loader = torch.utils.data.DataLoader(pairs, batch_size=configuration['batch_size'], shuffle=True)\n        val_loader = torch.utils.data.DataLoader(val_pairs, batch_size=configuration['batch_size'], shuffle=True)\n        test_loader = torch.utils.data.DataLoader(test_pairs, batch_size=1, shuffle=True)\n\n        trainIters(encoder1, decoder1, train_loader, val_loader, test_loader, config.learning_rate, configuration, True)\n\n    # if configuration['attention'] == False :\n    #     trainIters(encoder1, decoder1, train_loader, val_loader, test_loader, learning_rate, configuration, True)\n\n# main()\n\n#wandb.init(project = 'Assignment_3', entity = 'samruddhipatil2526')\nwandb.agent(sweep_id, main, count = 20)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-05-17T05:26:34.648780Z","iopub.execute_input":"2024-05-17T05:26:34.649126Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Create sweep with ID: wr4s1cxm\nSweep URL: https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qny50gx2 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamruddhipatil2526\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_052642-qny50gx2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/qny50gx2' target=\"_blank\">warm-sweep-1</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/qny50gx2' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/qny50gx2</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"name":"stdout","text":"ep :  0  | train loss : 0.9959798126220707  | val loss : 0.7639406120777131  | val accuracy :  1.46484375\nep :  1  | train loss : 0.7233202877044669  | val loss : 0.6227178502082825  | val accuracy :  5.6396484375\nep :  2  | train loss : 0.6250614918231958  | val loss : 0.5569117742776872  | val accuracy :  7.32421875\nep :  3  | train loss : 0.5612232528686522  | val loss : 0.5410967934131621  | val accuracy :  11.279296875\nep :  4  | train loss : 0.5246916293382642  | val loss : 0.49437784790992734  | val accuracy :  10.7177734375\nep :  5  | train loss : 0.5045923003196713  | val loss : 0.50852643430233  | val accuracy :  15.4296875\nep :  6  | train loss : 0.4823392650842662  | val loss : 0.47333507895469684  | val accuracy :  15.8935546875\nep :  7  | train loss : 0.45275799264907785  | val loss : 0.46301242411136634  | val accuracy :  18.3837890625\nep :  8  | train loss : 0.4481380415201184  | val loss : 0.4478187757730484  | val accuracy :  18.75\nep :  9  | train loss : 0.431353016257286  | val loss : 0.4332582199573516  | val accuracy :  18.359375\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▅▃▃▂▂▂▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▃▃▅▅▇▇███</td></tr><tr><td>validation_loss</td><td>█▅▄▃▂▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.43135</td></tr><tr><td>validation_accuracy</td><td>18.35938</td></tr><tr><td>validation_loss</td><td>0.43326</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">warm-sweep-1</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/qny50gx2' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/qny50gx2</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_052642-qny50gx2/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hchtcr0e with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_053614-hchtcr0e</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/hchtcr0e' target=\"_blank\">misty-sweep-2</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/hchtcr0e' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/hchtcr0e</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"name":"stdout","text":"ep :  0  | train loss : 1.24528905582428  | val loss : 0.9998929166793824  | val accuracy :  0.0244140625\nep :  1  | train loss : 0.9631988475799561  | val loss : 0.7957443022727968  | val accuracy :  0.927734375\nep :  2  | train loss : 0.7381002824783323  | val loss : 0.6151840567588804  | val accuracy :  3.6376953125\nep :  3  | train loss : 0.6075582278251642  | val loss : 0.5300202071666718  | val accuracy :  7.421875\nep :  4  | train loss : 0.5448929289817805  | val loss : 0.4969428479671479  | val accuracy :  11.1328125\nep :  5  | train loss : 0.49412689805030824  | val loss : 0.4658757352828979  | val accuracy :  14.208984375\nep :  6  | train loss : 0.4729110693454742  | val loss : 0.4493951773643493  | val accuracy :  16.69921875\nep :  7  | train loss : 0.43149660778045634  | val loss : 0.4317544674873352  | val accuracy :  17.0166015625\nep :  8  | train loss : 0.4177530562877655  | val loss : 0.4362046182155609  | val accuracy :  18.4326171875\nep :  9  | train loss : 0.4101362917900083  | val loss : 0.4154456305503845  | val accuracy :  20.8251953125\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▆▄▃▂▂▂▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▂▃▅▆▇▇▇█</td></tr><tr><td>validation_loss</td><td>█▆▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.41014</td></tr><tr><td>validation_accuracy</td><td>20.8252</td></tr><tr><td>validation_loss</td><td>0.41545</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">misty-sweep-2</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/hchtcr0e' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/hchtcr0e</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_053614-hchtcr0e/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7wkf9oj5 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_054238-7wkf9oj5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/7wkf9oj5' target=\"_blank\">zany-sweep-3</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/7wkf9oj5' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/7wkf9oj5</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"name":"stdout","text":"ep :  0  | train loss : 0.9349789519548399  | val loss : 0.7115571314096453  | val accuracy :  2.9052734375\nep :  1  | train loss : 0.7078579340934761  | val loss : 0.648515413105488  | val accuracy :  4.0283203125\nep :  2  | train loss : 0.6626938763380055  | val loss : 0.6094657742977143  | val accuracy :  6.2744140625\nep :  3  | train loss : 0.6216711493492132  | val loss : 0.5944718730449678  | val accuracy :  8.49609375\nep :  4  | train loss : 0.6004038566708565  | val loss : 0.5622344297170633  | val accuracy :  8.056640625\nep :  5  | train loss : 0.5676001241207118  | val loss : 0.5350189682841302  | val accuracy :  9.3017578125\nep :  6  | train loss : 0.5504084409713749  | val loss : 0.5407110011577604  | val accuracy :  10.7421875\nep :  7  | train loss : 0.5425971352100367  | val loss : 0.5361834958195681  | val accuracy :  11.23046875\nep :  8  | train loss : 0.5303929729342454  | val loss : 0.5335341700911521  | val accuracy :  11.1328125\nep :  9  | train loss : 0.5238885595560067  | val loss : 0.5308801856637  | val accuracy :  11.81640625\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▄▃▃▂▂▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▂▄▅▅▆▇█▇█</td></tr><tr><td>validation_loss</td><td>█▆▄▃▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.52389</td></tr><tr><td>validation_accuracy</td><td>11.81641</td></tr><tr><td>validation_loss</td><td>0.53088</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">zany-sweep-3</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/7wkf9oj5' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/7wkf9oj5</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_054238-7wkf9oj5/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sd99xado with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_055648-sd99xado</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/sd99xado' target=\"_blank\">wandering-sweep-4</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/sd99xado' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/sd99xado</a>"},"metadata":{}},{"name":"stdout","text":"ep :  0  | train loss : 1.0178848074913034  | val loss : 0.7467405450344088  | val accuracy :  0.5859375\nep :  1  | train loss : 0.710842105102539  | val loss : 0.5966389298439028  | val accuracy :  4.443359375\nep :  2  | train loss : 0.6230865775585169  | val loss : 0.5643476289510726  | val accuracy :  6.103515625\nep :  3  | train loss : 0.5723875119686125  | val loss : 0.5306826138496398  | val accuracy :  9.4970703125\nep :  4  | train loss : 0.5338493308544159  | val loss : 0.5228085517883301  | val accuracy :  11.279296875\nep :  5  | train loss : 0.5121717365264897  | val loss : 0.506967777609825  | val accuracy :  13.4033203125\nep :  6  | train loss : 0.501272924995423  | val loss : 0.49172202229499806  | val accuracy :  12.6708984375\nep :  7  | train loss : 0.48699014387130724  | val loss : 0.47876088500022906  | val accuracy :  15.0390625\nep :  8  | train loss : 0.4787479133605953  | val loss : 0.48505579471588145  | val accuracy :  14.94140625\nep :  9  | train loss : 0.4791667072296141  | val loss : 0.4742154383659363  | val accuracy :  16.3330078125\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▄▃▂▂▁▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▃▃▅▆▇▆▇▇█</td></tr><tr><td>validation_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.47917</td></tr><tr><td>validation_accuracy</td><td>16.33301</td></tr><tr><td>validation_loss</td><td>0.47422</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">wandering-sweep-4</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/sd99xado' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/sd99xado</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_055648-sd99xado/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c1j06sba with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_060620-c1j06sba</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/c1j06sba' target=\"_blank\">splendid-sweep-5</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/c1j06sba' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/c1j06sba</a>"},"metadata":{}},{"name":"stdout","text":"ep :  0  | train loss : 0.9736241504907609  | val loss : 0.721842506825924  | val accuracy :  1.0498046875\nep :  1  | train loss : 0.7075648931741725  | val loss : 0.6051110526919367  | val accuracy :  4.931640625\nep :  2  | train loss : 0.6145466021060946  | val loss : 0.5730796852707861  | val accuracy :  8.3251953125\nep :  3  | train loss : 0.5768445823431013  | val loss : 0.5466050943732262  | val accuracy :  10.888671875\nep :  4  | train loss : 0.5528649607896806  | val loss : 0.5331340792775153  | val accuracy :  11.9873046875\nep :  5  | train loss : 0.5384702794551847  | val loss : 0.5222534546256066  | val accuracy :  11.4501953125\nep :  6  | train loss : 0.5302940493345263  | val loss : 0.5085448932647707  | val accuracy :  12.451171875\nep :  7  | train loss : 0.5203341313362118  | val loss : 0.5006300371885299  | val accuracy :  12.890625\nep :  8  | train loss : 0.5048530788779263  | val loss : 0.5034084203839301  | val accuracy :  13.2080078125\nep :  9  | train loss : 0.5053636517047877  | val loss : 0.4987397250533104  | val accuracy :  13.720703125\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.019 MB of 0.019 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▃▅▆▇▇▇███</td></tr><tr><td>validation_loss</td><td>█▄▃▃▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.50536</td></tr><tr><td>validation_accuracy</td><td>13.7207</td></tr><tr><td>validation_loss</td><td>0.49874</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">splendid-sweep-5</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/c1j06sba' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/c1j06sba</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_060620-c1j06sba/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ply3qhtj with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_063114-ply3qhtj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/ply3qhtj' target=\"_blank\">rural-sweep-6</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/ply3qhtj' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/ply3qhtj</a>"},"metadata":{}},{"name":"stdout","text":"ep :  0  | train loss : 1.219251584815978  | val loss : 0.9901049947738648  | val accuracy :  0.0\nep :  1  | train loss : 0.8573052552223211  | val loss : 0.6378718447685242  | val accuracy :  3.9306640625\nep :  2  | train loss : 0.590393955421447  | val loss : 0.5045588397979737  | val accuracy :  8.984375\nep :  3  | train loss : 0.4922001732349394  | val loss : 0.4464535892009734  | val accuracy :  15.3076171875\nep :  4  | train loss : 0.4403254193782806  | val loss : 0.41514432311058047  | val accuracy :  17.8466796875\nep :  5  | train loss : 0.40543422098159765  | val loss : 0.3979798698425293  | val accuracy :  21.4111328125\nep :  6  | train loss : 0.3724530145168304  | val loss : 0.38017256855964665  | val accuracy :  23.095703125\nep :  7  | train loss : 0.3598144251823421  | val loss : 0.38194087088108064  | val accuracy :  24.9755859375\nep :  8  | train loss : 0.3407164212703709  | val loss : 0.36980876386165606  | val accuracy :  26.953125\nep :  9  | train loss : 0.32305150327682497  | val loss : 0.3595357519388198  | val accuracy :  27.44140625\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▂▃▅▆▆▇▇██</td></tr><tr><td>validation_loss</td><td>█▄▃▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.32305</td></tr><tr><td>validation_accuracy</td><td>27.44141</td></tr><tr><td>validation_loss</td><td>0.35954</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rural-sweep-6</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/ply3qhtj' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/ply3qhtj</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_063114-ply3qhtj/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6pedb1v8 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_064144-6pedb1v8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/6pedb1v8' target=\"_blank\">wandering-sweep-7</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/6pedb1v8' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/6pedb1v8</a>"},"metadata":{}},{"name":"stdout","text":"ep :  0  | train loss : 1.2762180103301999  | val loss : 1.0213471627235413  | val accuracy :  0.0\nep :  1  | train loss : 1.116713551712036  | val loss : 0.9901698589324953  | val accuracy :  0.0\nep :  2  | train loss : 1.0305254903793333  | val loss : 0.8852300906181334  | val accuracy :  0.0244140625\nep :  3  | train loss : 0.938734447669983  | val loss : 0.7820861530303957  | val accuracy :  0.1953125\nep :  4  | train loss : 0.8081489223480236  | val loss : 0.6753667581081391  | val accuracy :  1.8798828125\nep :  5  | train loss : 0.6802726984024051  | val loss : 0.5664280891418456  | val accuracy :  5.517578125\nep :  6  | train loss : 0.5811729640007023  | val loss : 0.49810410380363473  | val accuracy :  9.08203125\nep :  7  | train loss : 0.5193462835311891  | val loss : 0.47394316911697393  | val accuracy :  10.7177734375\nep :  8  | train loss : 0.48419048924446095  | val loss : 0.4476900160312653  | val accuracy :  12.890625\nep :  9  | train loss : 0.45492207374572763  | val loss : 0.42981211781501777  | val accuracy :  16.1865234375\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▇▆▅▄▃▂▂▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▁▂▃▅▆▇█</td></tr><tr><td>validation_loss</td><td>██▆▅▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.45492</td></tr><tr><td>validation_accuracy</td><td>16.18652</td></tr><tr><td>validation_loss</td><td>0.42981</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">wandering-sweep-7</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/6pedb1v8' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/6pedb1v8</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_064144-6pedb1v8/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n3vragfa with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_065014-n3vragfa</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/n3vragfa' target=\"_blank\">misty-sweep-8</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/n3vragfa' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/n3vragfa</a>"},"metadata":{}},{"name":"stdout","text":"ep :  0  | train loss : 1.273778536033631  | val loss : 1.1543648290634156  | val accuracy :  0.0\nep :  1  | train loss : 1.1766351737976068  | val loss : 1.1443086075782778  | val accuracy :  0.0\nep :  2  | train loss : 1.1707219343185424  | val loss : 1.1586808180809018  | val accuracy :  0.0\nep :  3  | train loss : 1.1436465337753297  | val loss : 1.1658714866638185  | val accuracy :  0.0\nep :  4  | train loss : 1.1401755176544197  | val loss : 1.1543452620506287  | val accuracy :  0.0\nep :  5  | train loss : 1.1339416196823124  | val loss : 1.1478458166122432  | val accuracy :  0.0\nep :  6  | train loss : 1.1430768684387216  | val loss : 1.1664226579666142  | val accuracy :  0.0\nep :  7  | train loss : 1.1256816942214962  | val loss : 1.1613065910339355  | val accuracy :  0.0\nep :  8  | train loss : 1.1241129819869997  | val loss : 1.1542762756347655  | val accuracy :  0.0\nep :  9  | train loss : 1.135160351181031  | val loss : 1.1517285728454587  | val accuracy :  0.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▃▃▂▂▁▂▁▁▂</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>▄▁▆█▄▂█▆▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>1.13516</td></tr><tr><td>validation_accuracy</td><td>0.0</td></tr><tr><td>validation_loss</td><td>1.15173</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">misty-sweep-8</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/n3vragfa' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/n3vragfa</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_065014-n3vragfa/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hxxkmgiz with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_065801-hxxkmgiz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/hxxkmgiz' target=\"_blank\">resilient-sweep-9</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/hxxkmgiz' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/hxxkmgiz</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"name":"stdout","text":"ep :  0  | train loss : 1.2000474647521981  | val loss : 0.9412042522430422  | val accuracy :  0.048828125\nep :  1  | train loss : 0.9479376329421992  | val loss : 0.8351457643508912  | val accuracy :  0.48828125\nep :  2  | train loss : 0.839675189876557  | val loss : 0.7543781685829164  | val accuracy :  1.171875\nep :  3  | train loss : 0.7789453413963308  | val loss : 0.7150559091567992  | val accuracy :  2.3193359375\nep :  4  | train loss : 0.7232451472282406  | val loss : 0.6684839415550231  | val accuracy :  3.173828125\nep :  5  | train loss : 0.6926980728149412  | val loss : 0.6510516512393953  | val accuracy :  5.4443359375\nep :  6  | train loss : 0.6577730596542364  | val loss : 0.6144362080097198  | val accuracy :  6.73828125\nep :  7  | train loss : 0.6157169685363769  | val loss : 0.6306118047237399  | val accuracy :  7.763671875\nep :  8  | train loss : 0.6041767635345457  | val loss : 0.5660864722728729  | val accuracy :  7.5927734375\nep :  9  | train loss : 0.5803411145210261  | val loss : 0.5428335916996002  | val accuracy :  9.9365234375\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.019 MB uploaded\\r'), FloatProgress(value=0.07002066844784997, max=1.…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▅▄▃▃▂▂▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▂▃▃▅▆▆▆█</td></tr><tr><td>validation_loss</td><td>█▆▅▄▃▃▂▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.58034</td></tr><tr><td>validation_accuracy</td><td>9.93652</td></tr><tr><td>validation_loss</td><td>0.54283</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">resilient-sweep-9</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/hxxkmgiz' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/hxxkmgiz</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_065801-hxxkmgiz/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kpw6bnvs with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_070328-kpw6bnvs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/kpw6bnvs' target=\"_blank\">laced-sweep-10</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/kpw6bnvs' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/kpw6bnvs</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"name":"stdout","text":"ep :  0  | train loss : 1.0859934443473827  | val loss : 0.8167866849899291  | val accuracy :  0.6591796875\nep :  1  | train loss : 0.7151913614749907  | val loss : 0.5961892509460451  | val accuracy :  6.4453125\nep :  2  | train loss : 0.5816034362792966  | val loss : 0.5093889749050141  | val accuracy :  9.8388671875\nep :  3  | train loss : 0.5082354935884474  | val loss : 0.46309256017208106  | val accuracy :  13.1591796875\nep :  4  | train loss : 0.4600799700498576  | val loss : 0.4559062570333481  | val accuracy :  15.673828125\nep :  5  | train loss : 0.43110210893154116  | val loss : 0.43192438185215004  | val accuracy :  18.603515625\nep :  6  | train loss : 0.4006398843526843  | val loss : 0.42150750994682334  | val accuracy :  20.9716796875\nep :  7  | train loss : 0.3828679634332658  | val loss : 0.426901484131813  | val accuracy :  22.8759765625\nep :  8  | train loss : 0.37957626168727837  | val loss : 0.39654004812240606  | val accuracy :  24.3408203125\nep :  9  | train loss : 0.3645278427362447  | val loss : 0.3940266257524489  | val accuracy :  24.3896484375\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▃▄▅▅▆▇███</td></tr><tr><td>validation_loss</td><td>█▄▃▂▂▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.36453</td></tr><tr><td>validation_accuracy</td><td>24.38965</td></tr><tr><td>validation_loss</td><td>0.39403</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">laced-sweep-10</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/kpw6bnvs' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/kpw6bnvs</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_070328-kpw6bnvs/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 02tvtr0j with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_071304-02tvtr0j</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/02tvtr0j' target=\"_blank\">graceful-sweep-11</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/02tvtr0j' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/02tvtr0j</a>"},"metadata":{}},{"name":"stdout","text":"ep :  0  | train loss : 1.245664974594117  | val loss : 1.1864336037635803  | val accuracy :  0.0\nep :  1  | train loss : 1.1554804235458371  | val loss : 1.148561136722565  | val accuracy :  0.0\nep :  2  | train loss : 1.143657032203674  | val loss : 1.1737605857849118  | val accuracy :  0.0\nep :  3  | train loss : 1.1193002632141107  | val loss : 1.1513422107696534  | val accuracy :  0.0\nep :  4  | train loss : 1.1172472663879391  | val loss : 1.1553745770454404  | val accuracy :  0.0\nep :  5  | train loss : 1.1335521484375004  | val loss : 1.1469634652137757  | val accuracy :  0.0\nep :  6  | train loss : 1.1307941366195673  | val loss : 1.1598538064956663  | val accuracy :  0.0\nep :  7  | train loss : 1.0981663305282594  | val loss : 1.1735327243804934  | val accuracy :  0.0\nep :  8  | train loss : 1.1151995445251475  | val loss : 1.1528307151794435  | val accuracy :  0.0\nep :  9  | train loss : 1.114324074363708  | val loss : 1.2687716245651244  | val accuracy :  0.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▄▃▂▂▃▃▁▂▂</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>▃▁▃▁▁▁▂▃▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>1.11432</td></tr><tr><td>validation_accuracy</td><td>0.0</td></tr><tr><td>validation_loss</td><td>1.26877</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">graceful-sweep-11</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/02tvtr0j' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/02tvtr0j</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_071304-02tvtr0j/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fp66mmz0 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_072036-fp66mmz0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/fp66mmz0' target=\"_blank\">misunderstood-sweep-12</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/fp66mmz0' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/fp66mmz0</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"name":"stdout","text":"ep :  0  | train loss : 1.1766086362838752  | val loss : 0.9206032562255859  | val accuracy :  0.1220703125\nep :  1  | train loss : 0.9114319215774536  | val loss : 0.8219615817070007  | val accuracy :  1.2939453125\nep :  2  | train loss : 0.797185865974427  | val loss : 0.7140752530097962  | val accuracy :  1.5625\nep :  3  | train loss : 0.7378139847755434  | val loss : 0.6912567460536956  | val accuracy :  4.4921875\nep :  4  | train loss : 0.6569687745094298  | val loss : 0.6441038620471955  | val accuracy :  6.3720703125\nep :  5  | train loss : 0.6216193286895756  | val loss : 0.6145094013214112  | val accuracy :  7.958984375\nep :  6  | train loss : 0.5994953090667718  | val loss : 0.575274385213852  | val accuracy :  9.0576171875\nep :  7  | train loss : 0.5689279286384583  | val loss : 0.5422014653682709  | val accuracy :  8.740234375\nep :  8  | train loss : 0.5574912074089049  | val loss : 0.5292287993431091  | val accuracy :  10.4736328125\nep :  9  | train loss : 0.5385459500312806  | val loss : 0.5033340895175933  | val accuracy :  12.01171875\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▂▂▄▅▆▆▆▇█</td></tr><tr><td>validation_loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.53855</td></tr><tr><td>validation_accuracy</td><td>12.01172</td></tr><tr><td>validation_loss</td><td>0.50333</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">misunderstood-sweep-12</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/fp66mmz0' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/fp66mmz0</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_072036-fp66mmz0/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3ilvu0y3 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_072609-3ilvu0y3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/3ilvu0y3' target=\"_blank\">laced-sweep-13</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/3ilvu0y3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/3ilvu0y3</a>"},"metadata":{}},{"name":"stdout","text":"ep :  0  | train loss : 1.2737018177032475  | val loss : 1.071655592918396  | val accuracy :  0.0\nep :  1  | train loss : 1.057853424644471  | val loss : 0.8843236613273622  | val accuracy :  0.1220703125\nep :  2  | train loss : 0.8691702001571653  | val loss : 0.7054474472999575  | val accuracy :  1.2939453125\nep :  3  | train loss : 0.7063236801147456  | val loss : 0.5859911799430847  | val accuracy :  4.58984375\nep :  4  | train loss : 0.6103523632049562  | val loss : 0.5456655144691467  | val accuracy :  9.1064453125\nep :  5  | train loss : 0.5484780768394472  | val loss : 0.4921502256393433  | val accuracy :  10.546875\nep :  6  | train loss : 0.5021689752578736  | val loss : 0.4609121191501617  | val accuracy :  11.81640625\nep :  7  | train loss : 0.4680393371582026  | val loss : 0.46707073211669925  | val accuracy :  15.9912109375\nep :  8  | train loss : 0.4532557086467745  | val loss : 0.4404950869083404  | val accuracy :  16.4306640625\nep :  9  | train loss : 0.4414731310367588  | val loss : 0.4256565260887146  | val accuracy :  18.1884765625\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▆▅▃▂▂▂▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▃▅▅▆▇▇█</td></tr><tr><td>validation_loss</td><td>█▆▄▃▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.44147</td></tr><tr><td>validation_accuracy</td><td>18.18848</td></tr><tr><td>validation_loss</td><td>0.42566</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">laced-sweep-13</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/3ilvu0y3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/3ilvu0y3</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_072609-3ilvu0y3/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 71u86c2y with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_073238-71u86c2y</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/71u86c2y' target=\"_blank\">smooth-sweep-14</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/71u86c2y' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/71u86c2y</a>"},"metadata":{}},{"name":"stdout","text":"ep :  0  | train loss : 1.2452890508651728  | val loss : 1.1518842792510986  | val accuracy :  0.0\nep :  1  | train loss : 1.1671324789047244  | val loss : 1.174070043563843  | val accuracy :  0.0\nep :  2  | train loss : 1.1598476732254033  | val loss : 1.1434949374198913  | val accuracy :  0.0\nep :  3  | train loss : 1.1488455846786492  | val loss : 1.1509352731704712  | val accuracy :  0.0\nep :  4  | train loss : 1.1444977619171146  | val loss : 1.148844232559204  | val accuracy :  0.0\nep :  5  | train loss : 1.1309392295837404  | val loss : 1.1553643274307248  | val accuracy :  0.0\nep :  6  | train loss : 1.1166476455688472  | val loss : 1.1572041630744934  | val accuracy :  0.0\nep :  7  | train loss : 1.1357588922500614  | val loss : 1.1565524983406066  | val accuracy :  0.0\nep :  8  | train loss : 1.1151272731781001  | val loss : 1.1807154178619386  | val accuracy :  0.0\nep :  9  | train loss : 1.1417136358261109  | val loss : 1.1525188612937929  | val accuracy :  0.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.019 MB of 0.019 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▄▃▃▃▂▁▂▁▂</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>▃▇▁▂▂▃▄▃█▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>1.14171</td></tr><tr><td>validation_accuracy</td><td>0.0</td></tr><tr><td>validation_loss</td><td>1.15252</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">smooth-sweep-14</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/71u86c2y' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/71u86c2y</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_073238-71u86c2y/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r6yqbcin with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_073907-r6yqbcin</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/r6yqbcin' target=\"_blank\">ruby-sweep-15</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/r6yqbcin' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/r6yqbcin</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"name":"stdout","text":"ep :  0  | train loss : 1.1909214536190043  | val loss : 1.2255142039060594  | val accuracy :  0.0\nep :  1  | train loss : 1.1510698625087734  | val loss : 1.1411984521150593  | val accuracy :  0.0\nep :  2  | train loss : 1.1312039198875439  | val loss : 1.164978295564652  | val accuracy :  0.0\nep :  3  | train loss : 1.1240202140331286  | val loss : 1.179939859509468  | val accuracy :  0.0\nep :  4  | train loss : 1.1373410990238186  | val loss : 1.1551781928539278  | val accuracy :  0.0\nep :  5  | train loss : 1.1124553700447097  | val loss : 1.1565102928876867  | val accuracy :  0.0\nep :  6  | train loss : 1.1299103657245622  | val loss : 1.1912765753269197  | val accuracy :  0.0\nep :  7  | train loss : 1.1159791396141046  | val loss : 1.1580130988359454  | val accuracy :  0.0\nep :  8  | train loss : 1.1139803699016566  | val loss : 1.1887311321496967  | val accuracy :  0.0\nep :  9  | train loss : 1.1110150201320634  | val loss : 1.1756548112630854  | val accuracy :  0.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▅▃▂▃▁▃▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>█▁▃▄▂▂▅▂▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>1.11102</td></tr><tr><td>validation_accuracy</td><td>0.0</td></tr><tr><td>validation_loss</td><td>1.17565</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">ruby-sweep-15</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/r6yqbcin' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/r6yqbcin</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_073907-r6yqbcin/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: blklave9 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_075410-blklave9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/blklave9' target=\"_blank\">lunar-sweep-16</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/blklave9' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/blklave9</a>"},"metadata":{}},{"name":"stdout","text":"ep :  0  | train loss : 1.2694712799072252  | val loss : 1.0040684914588927  | val accuracy :  0.0\nep :  1  | train loss : 1.073971066093445  | val loss : 0.9206065392494202  | val accuracy :  0.0244140625\nep :  2  | train loss : 0.8709371803283691  | val loss : 0.6823148822784422  | val accuracy :  1.171875\nep :  3  | train loss : 0.6826630373001099  | val loss : 0.584095848798752  | val accuracy :  6.8359375\nep :  4  | train loss : 0.5884586327552791  | val loss : 0.5065111517906189  | val accuracy :  8.447265625\nep :  5  | train loss : 0.5053204417228695  | val loss : 0.48899513721466065  | val accuracy :  13.3544921875\nep :  6  | train loss : 0.475466038894653  | val loss : 0.45216178178787236  | val accuracy :  15.625\nep :  7  | train loss : 0.4453702092647553  | val loss : 0.45881771922111503  | val accuracy :  17.626953125\nep :  8  | train loss : 0.419848074245453  | val loss : 0.41997215628623963  | val accuracy :  19.189453125\nep :  9  | train loss : 0.4178171975135804  | val loss : 0.4027605366706848  | val accuracy :  20.3369140625\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▆▅▃▂▂▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▃▄▆▆▇██</td></tr><tr><td>validation_loss</td><td>█▇▄▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.41782</td></tr><tr><td>validation_accuracy</td><td>20.33691</td></tr><tr><td>validation_loss</td><td>0.40276</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lunar-sweep-16</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/blklave9' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/blklave9</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_075410-blklave9/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 39siqbnl with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_080049-39siqbnl</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/39siqbnl' target=\"_blank\">smart-sweep-17</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/sweeps/wr4s1cxm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/39siqbnl' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3/runs/39siqbnl</a>"},"metadata":{}},{"name":"stdout","text":"ep :  0  | train loss : 1.160268549728395  | val loss : 0.8233831357955934  | val accuracy :  0.2197265625\nep :  1  | train loss : 0.7058232266426084  | val loss : 0.5379182744026185  | val accuracy :  7.763671875\nep :  2  | train loss : 0.5199237816810608  | val loss : 0.47547334671020497  | val accuracy :  14.208984375\nep :  3  | train loss : 0.46061815171241755  | val loss : 0.4277462470531464  | val accuracy :  17.6025390625\nep :  4  | train loss : 0.4116797802448275  | val loss : 0.42270873546600335  | val accuracy :  21.6552734375\nep :  5  | train loss : 0.39128828792572007  | val loss : 0.3891694128513337  | val accuracy :  21.77734375\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install wandb\n!pip install kaggle","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:25:53.174888Z","iopub.execute_input":"2024-05-17T05:25:53.175264Z","iopub.status.idle":"2024-05-17T05:26:17.925309Z","shell.execute_reply.started":"2024-05-17T05:25:53.175234Z","shell.execute_reply":"2024-05-17T05:26:17.924230Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (1.6.12)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.16.0)\nRequirement already satisfied: certifi>=2023.7.22 in /opt/conda/lib/python3.10/site-packages (from kaggle) (2024.2.2)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.9.0.post0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle) (4.66.1)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle) (8.0.4)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.26.18)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle) (6.1.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle) (3.6)\n","output_type":"stream"}]},{"cell_type":"code","source":"!kaggle datasets download -d anon1729/aksharantar-sampled","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:26:19.741157Z","iopub.execute_input":"2024-05-17T05:26:19.741558Z","iopub.status.idle":"2024-05-17T05:26:24.632013Z","shell.execute_reply.started":"2024-05-17T05:26:19.741525Z","shell.execute_reply":"2024-05-17T05:26:24.630853Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Dataset URL: https://www.kaggle.com/datasets/anon1729/aksharantar-sampled\nLicense(s): unknown\nDownloading aksharantar-sampled.zip to /kaggle/working\n 78%|█████████████████████████████▋        | 11.0M/14.1M [00:01<00:00, 15.5MB/s]\n100%|██████████████████████████████████████| 14.1M/14.1M [00:01<00:00, 11.8MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!unzip aksharantar-sampled.zip\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:26:26.643954Z","iopub.execute_input":"2024-05-17T05:26:26.644344Z","iopub.status.idle":"2024-05-17T05:26:27.975829Z","shell.execute_reply.started":"2024-05-17T05:26:26.644313Z","shell.execute_reply":"2024-05-17T05:26:27.974877Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Archive:  aksharantar-sampled.zip\n  inflating: aksharantar_sampled/asm/asm_test.csv  \n  inflating: aksharantar_sampled/asm/asm_train.csv  \n  inflating: aksharantar_sampled/asm/asm_valid.csv  \n  inflating: aksharantar_sampled/ben/ben_test.csv  \n  inflating: aksharantar_sampled/ben/ben_train.csv  \n  inflating: aksharantar_sampled/ben/ben_valid.csv  \n  inflating: aksharantar_sampled/brx/brx_test.csv  \n  inflating: aksharantar_sampled/brx/brx_train.csv  \n  inflating: aksharantar_sampled/brx/brx_valid.csv  \n  inflating: aksharantar_sampled/guj/guj_test.csv  \n  inflating: aksharantar_sampled/guj/guj_train.csv  \n  inflating: aksharantar_sampled/guj/guj_valid.csv  \n  inflating: aksharantar_sampled/hin/hin_test.csv  \n  inflating: aksharantar_sampled/hin/hin_train.csv  \n  inflating: aksharantar_sampled/hin/hin_valid.csv  \n  inflating: aksharantar_sampled/kan/kan_test.csv  \n  inflating: aksharantar_sampled/kan/kan_train.csv  \n  inflating: aksharantar_sampled/kan/kan_valid.csv  \n  inflating: aksharantar_sampled/kas/kas_test.csv  \n  inflating: aksharantar_sampled/kas/kas_train.csv  \n  inflating: aksharantar_sampled/kas/kas_valid.csv  \n  inflating: aksharantar_sampled/kok/kok_test.csv  \n  inflating: aksharantar_sampled/kok/kok_train.csv  \n  inflating: aksharantar_sampled/kok/kok_valid.csv  \n  inflating: aksharantar_sampled/mai/mai_test.csv  \n  inflating: aksharantar_sampled/mai/mai_train.csv  \n  inflating: aksharantar_sampled/mai/mai_valid.csv  \n  inflating: aksharantar_sampled/mal/mal_test.csv  \n  inflating: aksharantar_sampled/mal/mal_train.csv  \n  inflating: aksharantar_sampled/mal/mal_valid.csv  \n  inflating: aksharantar_sampled/mar/mar_test.csv  \n  inflating: aksharantar_sampled/mar/mar_train.csv  \n  inflating: aksharantar_sampled/mar/mar_valid.csv  \n  inflating: aksharantar_sampled/mni/mni_test.csv  \n  inflating: aksharantar_sampled/mni/mni_train.csv  \n  inflating: aksharantar_sampled/mni/mni_valid.csv  \n  inflating: aksharantar_sampled/ori/ori_test.csv  \n  inflating: aksharantar_sampled/ori/ori_train.csv  \n  inflating: aksharantar_sampled/ori/ori_valid.csv  \n  inflating: aksharantar_sampled/pan/pan_test.csv  \n  inflating: aksharantar_sampled/pan/pan_train.csv  \n  inflating: aksharantar_sampled/pan/pan_valid.csv  \n  inflating: aksharantar_sampled/san/san_test.csv  \n  inflating: aksharantar_sampled/san/san_train.csv  \n  inflating: aksharantar_sampled/san/san_valid.csv  \n  inflating: aksharantar_sampled/sid/sid_test.csv  \n  inflating: aksharantar_sampled/sid/sid_train.csv  \n  inflating: aksharantar_sampled/sid/sid_valid.csv  \n  inflating: aksharantar_sampled/tam/tam_test.csv  \n  inflating: aksharantar_sampled/tam/tam_train.csv  \n  inflating: aksharantar_sampled/tam/tam_valid.csv  \n  inflating: aksharantar_sampled/tel/tel_test.csv  \n  inflating: aksharantar_sampled/tel/tel_train.csv  \n  inflating: aksharantar_sampled/tel/tel_valid.csv  \n  inflating: aksharantar_sampled/urd/urd_test.csv  \n  inflating: aksharantar_sampled/urd/urd_train.csv  \n  inflating: aksharantar_sampled/urd/urd_valid.csv  \n","output_type":"stream"}]}]}