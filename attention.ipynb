{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":19.297542,"end_time":"2023-05-05T08:04:35.711536","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-05-05T08:04:16.413994","version":"2.4.0"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb\n!pip install kaggle\n!kaggle datasets download -d anon1729/aksharantar-sampled\n!unzip aksharantar-sampled.zip","metadata":{"execution":{"iopub.status.busy":"2024-05-17T08:09:26.125619Z","iopub.execute_input":"2024-05-17T08:09:26.126295Z","iopub.status.idle":"2024-05-17T08:09:55.959837Z","shell.execute_reply.started":"2024-05-17T08:09:26.126259Z","shell.execute_reply":"2024-05-17T08:09:55.958711Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (1.6.12)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.16.0)\nRequirement already satisfied: certifi>=2023.7.22 in /opt/conda/lib/python3.10/site-packages (from kaggle) (2024.2.2)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.9.0.post0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle) (4.66.1)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle) (8.0.4)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.26.18)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle) (6.1.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle) (3.6)\nDataset URL: https://www.kaggle.com/datasets/anon1729/aksharantar-sampled\nLicense(s): unknown\nDownloading aksharantar-sampled.zip to /kaggle/working\n 99%|█████████████████████████████████████▋| 14.0M/14.1M [00:01<00:00, 17.3MB/s]\n100%|██████████████████████████████████████| 14.1M/14.1M [00:01<00:00, 10.9MB/s]\nArchive:  aksharantar-sampled.zip\n  inflating: aksharantar_sampled/asm/asm_test.csv  \n  inflating: aksharantar_sampled/asm/asm_train.csv  \n  inflating: aksharantar_sampled/asm/asm_valid.csv  \n  inflating: aksharantar_sampled/ben/ben_test.csv  \n  inflating: aksharantar_sampled/ben/ben_train.csv  \n  inflating: aksharantar_sampled/ben/ben_valid.csv  \n  inflating: aksharantar_sampled/brx/brx_test.csv  \n  inflating: aksharantar_sampled/brx/brx_train.csv  \n  inflating: aksharantar_sampled/brx/brx_valid.csv  \n  inflating: aksharantar_sampled/guj/guj_test.csv  \n  inflating: aksharantar_sampled/guj/guj_train.csv  \n  inflating: aksharantar_sampled/guj/guj_valid.csv  \n  inflating: aksharantar_sampled/hin/hin_test.csv  \n  inflating: aksharantar_sampled/hin/hin_train.csv  \n  inflating: aksharantar_sampled/hin/hin_valid.csv  \n  inflating: aksharantar_sampled/kan/kan_test.csv  \n  inflating: aksharantar_sampled/kan/kan_train.csv  \n  inflating: aksharantar_sampled/kan/kan_valid.csv  \n  inflating: aksharantar_sampled/kas/kas_test.csv  \n  inflating: aksharantar_sampled/kas/kas_train.csv  \n  inflating: aksharantar_sampled/kas/kas_valid.csv  \n  inflating: aksharantar_sampled/kok/kok_test.csv  \n  inflating: aksharantar_sampled/kok/kok_train.csv  \n  inflating: aksharantar_sampled/kok/kok_valid.csv  \n  inflating: aksharantar_sampled/mai/mai_test.csv  \n  inflating: aksharantar_sampled/mai/mai_train.csv  \n  inflating: aksharantar_sampled/mai/mai_valid.csv  \n  inflating: aksharantar_sampled/mal/mal_test.csv  \n  inflating: aksharantar_sampled/mal/mal_train.csv  \n  inflating: aksharantar_sampled/mal/mal_valid.csv  \n  inflating: aksharantar_sampled/mar/mar_test.csv  \n  inflating: aksharantar_sampled/mar/mar_train.csv  \n  inflating: aksharantar_sampled/mar/mar_valid.csv  \n  inflating: aksharantar_sampled/mni/mni_test.csv  \n  inflating: aksharantar_sampled/mni/mni_train.csv  \n  inflating: aksharantar_sampled/mni/mni_valid.csv  \n  inflating: aksharantar_sampled/ori/ori_test.csv  \n  inflating: aksharantar_sampled/ori/ori_train.csv  \n  inflating: aksharantar_sampled/ori/ori_valid.csv  \n  inflating: aksharantar_sampled/pan/pan_test.csv  \n  inflating: aksharantar_sampled/pan/pan_train.csv  \n  inflating: aksharantar_sampled/pan/pan_valid.csv  \n  inflating: aksharantar_sampled/san/san_test.csv  \n  inflating: aksharantar_sampled/san/san_train.csv  \n  inflating: aksharantar_sampled/san/san_valid.csv  \n  inflating: aksharantar_sampled/sid/sid_test.csv  \n  inflating: aksharantar_sampled/sid/sid_train.csv  \n  inflating: aksharantar_sampled/sid/sid_valid.csv  \n  inflating: aksharantar_sampled/tam/tam_test.csv  \n  inflating: aksharantar_sampled/tam/tam_train.csv  \n  inflating: aksharantar_sampled/tam/tam_valid.csv  \n  inflating: aksharantar_sampled/tel/tel_test.csv  \n  inflating: aksharantar_sampled/tel/tel_train.csv  \n  inflating: aksharantar_sampled/tel/tel_valid.csv  \n  inflating: aksharantar_sampled/urd/urd_test.csv  \n  inflating: aksharantar_sampled/urd/urd_train.csv  \n  inflating: aksharantar_sampled/urd/urd_valid.csv  \n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport wandb\nimport torch\nimport random\nimport argparse\nimport pandas as pd\nimport torch.nn as nn\nimport torch.optim as optim\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\n### Create an argument parser object\n# parser=argparse.ArgumentParser()\n\n### Define command-line arguments with descriptions, data types, default values, and choices where applicable\n### WandB project name\n# parser.add_argument('-wp',      '--wandb_project',      help='project name',                                                    type=str,       default='CS6910_A3_')\n\n### WandB entity name\n# parser.add_argument('-we',      '--wandb_entity',       help='entity name',                                                     type=str,       default='cs22m064'  )\n\n### Number of Epochs\n# parser.add_argument('-e',       '--epochs',             help='epochs',                          choices=[5,10],                 type=int,       default=5           )\n\n### Batch Size\n# parser.add_argument('-b',       '--batch_size',         help='batch sizes',                     choices=[32,64,128],            type=int,       default=32          )\n\n### Optimizer Choice\n# parser.add_argument('-o',       '--optimizer',          help='optimizer',                       choices=['adam','nadam'],       type=str,       default='adam'      )\n\n### Learning Rate\n# parser.add_argument('-lr',      '--learning_rate',      help='learning rates',                  choices=[1e-2,1e-3],            type=float,     default=1e-2        )\n\n### Number Of layers in Encoder\n# parser.add_argument('-nle',     '--num_layers_en',      help='number of layers in encoder',     choices=[1,2,3],                type=int,       default=2           )\n\n### Number of layers in Decoder\n# parser.add_argument('-nld',     '--num_layers_dec',     help='number of layers in decoder',     choices=[1,2,3],                type=int,       default=2           )\n# parser.add_argument('-sz',      '--hidden_size',        help='hidden layer size',               choices=[16,32,64,256],         type=int,       default=256         )\n\n### Add Input Language\n# parser.add_argument('-il',      '--input_lang',         help='input language',                  choices=['hin','tel'],          type=str,       default='hin'       )\n\n### Add target Language\n# parser.add_argument('-tl',      '--target_lang',        help='target language',                 choices=['hin','tel'],          type=str,       default='hin'       )\n\n### Select Cell Type :LSTM , GRU, RNN\n# parser.add_argument('-ct',      '--cell_type',          help='cell type',                       choices=['LSTM','GRU','RNN'],   type=str,       default='LSTM'      )\n\n### Select Drop out value\n# parser.add_argument('-do',      '--drop_out',           help='drop out',                        choices=[0.0,0.2,0.3],          type=float,     default='0.2'       )\n\n### Select Embedding size\n# parser.add_argument('-es',      '--embedding_size',     help='embedding size',                  choices=[16,32,64,256],         type=int,       default=256         )\n\n### Bidirectional true or false\n# parser.add_argument('-bd',      '--bidirectional',      help='bidirectional',                   choices=[True,False],           type=bool,      default=False       )\n\n### Attention True or False\n# parser.add_argument('-at',      '--attention',          help='attention',                       choices=[True,False],           type=bool,      default=True        )\n\n# args=parser.parse_args()\n\n\nproject_name_ap     = 'Assifnment_3_att'\nentity_name_ap      = 'samruddhipatil2526'\n# epochs_ap           = args.epochs\n# batch_size_ap       = args.batch_size\n# optimizer_ap        = args.optimizer\n# learning_rate_ap    = args.learning_rate\n# num_layers_en_ap    = args.num_layers_en\n# num_layers_dec_ap   = args.num_layers_dec\n# hidden_size_ap      = args.hidden_size\ninput_lang_ap       = 'eng'\ntarget_lang_ap      = 'hin'\n# cell_type_ap        = args.cell_type\n# drop_out_ap         = args.drop_out\n# embedding_size_ap   = args.embedding_size\nbidirectional_ap    = False\nattention_ap        = True\n\n### Define the directory path where the data is located\ndir = '/kaggle/working/aksharantar_sampled'\n\n\n### Check if CUDA is available for GPU acceleration\nuse_cuda = torch.cuda.is_available()\n\n\n# Define special tokens for the vocabulary\n### Start-of-sequence token\nSOS_token = 0\n### End-of-sequence token\nEOS_token = 1\n### Unknown token\nUNK_token = 3\n### Padding token\nPAD_token = 4\n\n### # Define the sweep configuration using Bayesian optimization method\nsweep_config ={\n    'method':'bayes'\n}\n\nmetric = {\n    'name' : 'validation_accuracy',\n    'goal' : 'maximize'\n}\nsweep_config['metric'] = metric\n\nparameters_dict={\n    'epochs':{\n        'values' : [5,10]\n    },\n    'hidden_size':{\n        'values' : [128,256,512]\n    },\n    'cell_type':{\n        'values' : ['LSTM','RNN','GRU']\n    },\n    'learning_rate':{\n        'values' : [1e-2,1e-3]\n    },\n    'num_layers_en':{\n        'values' : [1,2,3]\n    },\n    'num_layers_dec':{\n        'values' : [1,2,3]\n    },\n    'drop_out':{\n        'values' : [0.0,0.2,0.3]\n    },\n    'embedding_size':{\n        'values' : [64,128,256]\n    },\n    'batch_size':{\n        'values' : [32,64,128]\n    },\n    'optimizer':{\n        'values' : ['adam','nadam']\n    },\n    'bidirectional':{\n        'values' : [True,False]\n    }\n}\nsweep_config['parameters'] = parameters_dict\n\nsweep_id = wandb.sweep(sweep_config, project=project_name_ap)\nprint(sweep_id)\n\nclass Vocabulary:\n\n    def __init__(self, name):\n        self.char2count = {}\n        self.char2index = {}\n        self.n_chars = 4\n        self.index2char = {0: '<', 1: '>',2 : '?', 3:'.'}\n        self.name = name\n\n    def addWord(self, word):\n        for char in word:\n            if char not in self.char2index:\n                self.char2index[char] = self.n_chars\n                self.index2char[self.n_chars] = char\n                self.char2count[char] = 1\n                self.n_chars += 1\n            else:\n                self.char2count[char] += 1\n        \n\ndef prepareData(dir, lang1, lang2):\n\n    data = pd.read_csv(dir,sep=\",\",names=['input', 'target'])\n    max_input_length = max([len(txt) for txt in data['input'].to_list()])\n    max_target_length = max([len(txt) for txt in data['target'].to_list()])\n\n    input_lang = Vocabulary(lang1)\n    output_lang = Vocabulary(lang2)\n\n    pairs = []\n    input_list,target_list = data['input'].to_list(),data['target'].to_list()\n    for i in range(len(input_list)):\n        pairs.append([input_list[i],target_list[i]])\n\n    for pair in pairs:\n        input_lang.addWord(pair[0])\n        output_lang.addWord(pair[1])\n\n    prepared_data = {\n        'input_lang' : input_lang,\n        'output_lang' : output_lang,\n        'pairs' : pairs,\n        'max_input_length' : max_input_length,\n        'max_target_length' : max_target_length\n    }\n\n    return prepared_data\n\nclass EncoderRNN(nn.Module):\n    \"\"\"\n        Initialize the EncoderRNN module.\n\n        Args:\n            input_size (int): Size of the input vocabulary.\n            configuration (dict): Configuration dictionary containing model parameters.\n\n        Configuration Parameters:\n            - embedding_size (int): Size of the embedding layer.\n            - hidden_size (int): Size of the hidden state.\n            - num_layers_encoder (int): Number of layers in the encoder.\n            - cell_type (str): Type of RNN cell ('RNN', 'GRU', or 'LSTM').\n            - drop_out (float): Dropout rate.\n            - bi_directional (bool): Whether the encoder is bidirectional.\n        \"\"\"\n    def __init__(self, input_size, configuration):\n        super(EncoderRNN, self).__init__()\n\n        self.embedding_size = configuration['embedding_size']\n        self.hidden_size = configuration['hidden_size']\n        self.num_layers_encoder = configuration[\"num_layers_encoder\"]\n        self.cell_type = configuration[\"cell_type\"]\n        self.drop_out = configuration['drop_out']\n        self.bi_directional = configuration['bi_directional']\n\n        self.embedding = nn.Embedding(input_size, self.embedding_size)\n        self.dropout = nn.Dropout(self.drop_out)\n        self.cell_layer = None\n        if self.cell_type == 'RNN':\n            self.cell_layer = nn.RNN(self.embedding_size, self.hidden_size, num_layers = self.num_layers_encoder, dropout = self.drop_out, bidirectional = self.bi_directional)\n        elif self.cell_type == 'GRU':\n            self.cell_layer = nn.GRU(self.embedding_size, self.hidden_size, num_layers = self.num_layers_encoder, dropout = self.drop_out, bidirectional = self.bi_directional)\n        elif self.cell_type == 'LSTM':\n            self.cell_layer = nn.LSTM(self.embedding_size, self.hidden_size, num_layers = self.num_layers_encoder, dropout = self.drop_out, bidirectional = self.bi_directional)\n \n    def forward(self, input, batch_size, hidden):\n                \"\"\"\n        Forward pass of the EncoderRNN.\n\n        Args:\n            input (Tensor): Input tensor containing indices of input sequence.\n            batch_size (int): Size of the input batch.\n            hidden (Tensor): Initial hidden state.\n\n        Returns:\n            output (Tensor): Output tensor from the RNN layer.\n            hidden (Tensor): Hidden state tensor.\n        \"\"\"\n        embedded = self.dropout(self.embedding(input).view(1,batch_size, -1))\n        output = embedded\n        output, hidden = self.cell_layer(output, hidden)\n        return output, hidden\n\n    def initHidden(self ,batch_size, num_layers_enc):\n        \"\"\"\n        Initialize the hidden state tensor.\n\n        Args:\n            batch_size (int): Size of the input batch.\n            num_layers_enc (int): Number of layers in the encoder.\n\n        Returns:\n            Tensor: Initialized hidden state tensor.\n        \"\"\"\n        res = None\n        if self.bi_directional:\n            res = torch.zeros(num_layers_enc* 2, batch_size, self.hidden_size)\n        else:\n            res = torch.zeros(num_layers_enc, batch_size, self.hidden_size)\n        if use_cuda : \n            return res.cuda()\n        else :\n            return res\n\nclass DecoderRNN(nn.Module):\n    def __init__(self, configuration,  output_size):\n        \"\"\"\n        Initialize the DecoderRNN module.\n\n        Args:\n            configuration (dict): Configuration dictionary containing model parameters.\n            output_size (int): Size of the output vocabulary.\n        \n        Configuration Parameters:\n            - embedding_size (int): Size of the embedding layer.\n            - hidden_size (int): Size of the hidden state.\n            - num_layers_decoder (int): Number of layers in the decoder.\n            - cell_type (str): Type of RNN cell ('RNN', 'GRU', or 'LSTM').\n            - drop_out (float): Dropout rate.\n            - bi_directional (bool): Whether the decoder is bidirectional.\n        \"\"\"\n        super(DecoderRNN, self).__init__()\n\n        self.embedding_size = configuration['embedding_size']\n        self.hidden_size = configuration['hidden_size']\n        self.num_layers_decoder = configuration[\"num_layers_decoder\"]\n        self.cell_type = configuration[\"cell_type\"]\n        self.drop_out = configuration[\"drop_out\"]\n        self.bi_directional = configuration[\"bi_directional\"]\n        self.dropout = nn.Dropout(self.drop_out)\n        \n        self.embedding = nn.Embedding(output_size, self.embedding_size)\n\n        self.cell_layer = None\n        if self.cell_type == 'RNN':\n            self.cell_layer = nn.RNN(self.embedding_size, self.hidden_size, num_layers = self.num_layers_decoder, dropout = self.drop_out, bidirectional = self.bi_directional)\n        elif self.cell_type == 'GRU':\n            self.cell_layer =   nn.GRU(self.embedding_size, self.hidden_size, num_layers = self.num_layers_decoder, dropout = self.drop_out, bidirectional = self.bi_directional)\n        elif self.cell_type == 'LSTM':\n            self.cell_layer = nn.LSTM(self.embedding_size, self.hidden_size, num_layers = self.num_layers_decoder, dropout = self.drop_out, bidirectional = self.bi_directional)\n        \n        if self.bi_directional:\n            self.out = nn.Linear(self.hidden_size * 2 ,output_size)\n        else:\n            self.out = nn.Linear(self.hidden_size, output_size)\n        \n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, batch_size, hidden):\n        \n        output = self.dropout(self.embedding(input).view(1,batch_size, -1))\n        output = F.relu(output)\n        output, hidden = self.cell_layer(output, hidden)\n        \n        output = self.softmax(self.out(output[0]))\n        return output, hidden\n\nclass DecoderAttention(nn.Module) :\n\n    def __init__(self, configs, output_size) :\n\n        super(DecoderAttention, self).__init__()\n        \n        self.hidden_size = configs['hidden_size']\n        self.embedding_size = configs['embedding_size']\n        self.cell_type = configs['cell_type']\n        self.num_layers_decoder = configs['num_layers_decoder']\n        self.drop_out = configs['drop_out']\n        self.max_length_word = configs['max_length_word']\n\n        self.embedding = nn.Embedding(output_size, embedding_dim = self.embedding_size)\n        self.attention_layer = nn.Linear(self.embedding_size + self.hidden_size, self.max_length_word + 1)\n        self.attention_combine = nn.Linear(self.embedding_size + self.hidden_size, self.embedding_size)\n        self.dropout = nn.Dropout(self.drop_out)\n\n        self.cell_layer = None\n        if self.cell_type == 'RNN':\n            self.cell_layer = nn.RNN(self.embedding_size, self.hidden_size, num_layers = self.num_layers_decoder, dropout = self.drop_out)\n        elif self.cell_type == 'GRU':\n            self.cell_layer =   nn.GRU(self.embedding_size, self.hidden_size, num_layers = self.num_layers_decoder, dropout = self.drop_out)\n        elif self.cell_type == 'LSTM':\n            self.cell_layer = nn.LSTM(self.embedding_size, self.hidden_size, num_layers = self.num_layers_decoder, dropout = self.drop_out)\n        self.out = nn.Linear(self.hidden_size, output_size)\n\n    def forward(self, input, batch_size, hidden, encoder_outputs) :\n        \n        embedded = self.embedding(input).view(1, batch_size, -1)\n        \n        attention_weights = None\n        if self.cell_type == 'LSTM' :\n            attention_weights = F.softmax(self.attention_layer(torch.cat((embedded[0], hidden[0][0]), 1)), dim = 1)\n        \n        else :\n            attention_weights = F.softmax(self.attention_layer(torch.cat((embedded[0], hidden[0]), 1)), dim = 1)\n\n        attention_applied = torch.bmm(attention_weights.view(batch_size,1,self.max_length_word+1), encoder_outputs).view(1,batch_size,-1)\n        output = torch.cat((embedded[0], attention_applied[0]), 1)\n        output = self.attention_combine(output).unsqueeze(0)\n        output = F.relu(output)\n        output, hidden = self.cell_layer(output, hidden)\n        output = F.log_softmax(self.out(output[0]), dim = 1)\n        \n        return output, hidden, attention_weights\n\ndef indexesFromWord(lang, word):\n    \"\"\"\n    Convert a word into a list of indices based on the character-to-index mapping of the language.\n\n    Args:\n        lang (Lang): Language object containing the character-to-index mapping.\n        word (str): Input word to convert into indices.\n\n    Returns:\n        index_list (list): List of indices corresponding to the characters in the word.\n    \"\"\"\n    index_list = []\n    for char in word:\n        if char in lang.char2index.keys():\n            index_list.append(lang.char2index[char])\n        else:\n            index_list.append(UNK_token)\n    return index_list\n\ndef variableFromSentence(lang, word, max_length):\n    \"\"\"\n    Convert a word into a PyTorch tensor variable.\n\n    Args:\n        lang (Lang): Language object.\n        word (str): Input word to convert.\n        max_length (int): Maximum length of the sequence.\n\n    Returns:\n        result (Tensor): PyTorch tensor variable representing the input word.\n    \"\"\"\n    indexes = indexesFromWord(lang, word)\n    indexes.append(EOS_token)\n    indexes.extend([PAD_token] * (max_length - len(indexes)))\n    result = torch.LongTensor(indexes)\n    if use_cuda:\n        return result.cuda()\n    else:\n        return result\n\ndef variablesFromPairs(input_lang, output_lang, pairs, max_length):\n    \"\"\"\n    Convert a list of word pairs into PyTorch tensor variables.\n\n    Args:\n        input_lang (Lang): Language object for the input language.\n        output_lang (Lang): Language object for the output language.\n        pairs (list): List of word pairs.\n        max_length (int): Maximum length of the sequence.\n\n    Returns:\n        res (list): List of tuples containing input and target tensor variables.\n    \"\"\"\n    res = []\n    for pair in pairs:\n        input_variable = variableFromSentence(input_lang, pair[0], max_length)\n        target_variable = variableFromSentence(output_lang, pair[1], max_length)\n        res.append((input_variable, target_variable))\n    return res\n\ndef train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, configuration, max_length, teacher_forcing_ratio = 0.5):\n    \n    batch_size = configuration['batch_size']\n    num_layers_enc = configuration['num_layers_encoder']\n    encoder_hidden = encoder.initHidden(batch_size,num_layers_enc)\n\n    input_tensor = Variable(input_tensor.transpose(0, 1))\n    target_tensor = Variable(target_tensor.transpose(0, 1))\n\n    if configuration[\"cell_type\"] == \"LSTM\":\n        encoder_cell_state = encoder.initHidden(batch_size,num_layers_enc)\n        encoder_hidden = (encoder_hidden, encoder_cell_state)\n\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n\n    loss = 0\n\n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(input_tensor[ei], batch_size, encoder_hidden)\n\n    decoder_input = Variable(torch.LongTensor([SOS_token]*batch_size))\n    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n\n    decoder_hidden = encoder_hidden\n\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    if use_teacher_forcing:\n        for di in range(target_length):\n            decoder_output, decoder_hidden= decoder(decoder_input, batch_size, decoder_hidden)\n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di]\n\n    else:\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(decoder_input, batch_size,decoder_hidden)\n            topv, topi = decoder_output.data.topk(1)\n            decoder_input = torch.cat(tuple(topi))\n\n            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n\n            loss += criterion(decoder_output, target_tensor[di])\n\n    loss.backward()\n\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n\n    return loss.item() / target_length\n  \ndef cal_val_loss(encoder, decoder, input_tensor, target_tensor, configuration, criterion , max_length):\n\n    with torch.no_grad():\n\n        batch_size = configuration['batch_size']\n        num_layers_enc = configuration['num_layers_encoder']\n        encoder_hidden = encoder.initHidden(batch_size,num_layers_enc)\n\n        input_tensor = Variable(input_tensor.transpose(0, 1))\n        target_tensor = Variable(target_tensor.transpose(0, 1))\n            \n        if configuration[\"cell_type\"] == \"LSTM\":\n            encoder_cell_state = encoder.initHidden(batch_size,num_layers_enc)\n            encoder_hidden = (encoder_hidden, encoder_cell_state)\n\n        input_length = input_tensor.size()[0]\n        target_length = target_tensor.size()[0]\n\n        loss = 0\n            \n        for ei in range(input_length):\n            encoder_output, encoder_hidden = encoder(input_tensor[ei], batch_size, encoder_hidden)\n\n        decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size))\n        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n\n        decoder_hidden = encoder_hidden\n\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(decoder_input, batch_size, decoder_hidden)\n            topv, topi = decoder_output.data.topk(1)\n            decoder_input = torch.cat(tuple(topi))\n\n            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n            loss += criterion(decoder_output, target_tensor[di])\n\n    return loss.item() / target_length\n\ndef evaluate(encoder, decoder, loader, configuration, criterion , max_length):\n\n    with torch.no_grad():\n\n        batch_size = configuration['batch_size']\n        total = 0\n        correct = 0\n        \n        for batch_x, batch_y in loader:\n            num_layers_enc = configuration['num_layers_encoder']\n            encoder_hidden = encoder.initHidden(batch_size,num_layers_enc)\n\n            input_variable = Variable(batch_x.transpose(0, 1))\n            target_variable = Variable(batch_y.transpose(0, 1))\n            \n            if configuration[\"cell_type\"] == \"LSTM\":\n                encoder_cell_state = encoder.initHidden(batch_size,num_layers_enc)\n                encoder_hidden = (encoder_hidden, encoder_cell_state)\n\n            input_length = input_variable.size()[0]\n            target_length = target_variable.size()[0]\n\n            output = torch.LongTensor(target_length, batch_size)\n\n            encoder_outputs = Variable(torch.zeros(max_length, batch_size, encoder.hidden_size))\n            encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n            \n            for ei in range(input_length):\n                encoder_output, encoder_hidden = encoder(input_variable[ei], batch_size, encoder_hidden)\n\n            decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size))\n            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n\n            decoder_hidden = encoder_hidden\n\n            for di in range(target_length):\n                decoder_output, decoder_hidden = decoder(decoder_input, batch_size, decoder_hidden)\n                topv, topi = decoder_output.data.topk(1)\n                decoder_input = torch.cat(tuple(topi))\n                output[di] = torch.cat(tuple(topi))\n\n            output = output.transpose(0,1)\n            for di in range(output.size()[0]):\n                ignore = [SOS_token, EOS_token, PAD_token]\n                sent = [configuration['output_lang'].index2char[letter.item()] for letter in output[di] if letter not in ignore]\n                y = [configuration['output_lang'].index2char[letter.item()] for letter in batch_y[di] if letter not in ignore]\n                if sent == y:\n                    correct += 1\n                total += 1\n\n    return (correct/total)*100\n\ndef train_with_attn(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, configuration, max_length, teacher_forcing_ratio = 0.5):\n    \n    batch_size = configuration['batch_size']\n    num_layers_enc = configuration['num_layers_encoder']\n    encoder_hidden = encoder.initHidden(batch_size,num_layers_enc)\n\n    input_tensor = Variable(input_tensor.transpose(0, 1))\n    target_tensor = Variable(target_tensor.transpose(0, 1))\n\n    if configuration[\"cell_type\"] == \"LSTM\":\n        encoder_cell_state = encoder.initHidden(batch_size,num_layers_enc)\n        encoder_hidden = (encoder_hidden, encoder_cell_state)\n\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n\n    encoder_outputs = Variable(torch.zeros(max_length, batch_size, encoder.hidden_size))\n    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n\n    loss = 0\n\n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(input_tensor[ei], batch_size, encoder_hidden)\n        encoder_outputs[ei] = encoder_output[0]\n\n    decoder_input = Variable(torch.LongTensor([SOS_token]*batch_size))\n    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n\n    decoder_hidden = encoder_hidden\n\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    if use_teacher_forcing:\n        for di in range(target_length):\n            decoder_output, decoder_hidden, decoder_attention= decoder(decoder_input, batch_size, decoder_hidden, encoder_outputs.reshape(batch_size,max_length, encoder.hidden_size))\n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di]\n\n    else:\n        for di in range(target_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, batch_size,decoder_hidden, encoder_outputs.reshape(batch_size,max_length, encoder.hidden_size))\n            topv, topi = decoder_output.data.topk(1)\n            decoder_input = torch.cat(tuple(topi))\n\n            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n\n            loss += criterion(decoder_output, target_tensor[di])\n\n    loss.backward()\n\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n\n    return loss.item() / target_length\n\ndef evaluate_with_attn(encoder, decoder, loader, configuration, criterion , max_length):\n\n    with torch.no_grad():\n\n        batch_size = configuration['batch_size']\n        total = 0\n        correct = 0\n        \n        for batch_x, batch_y in loader:\n\n            num_layers_enc = configuration['num_layers_encoder']\n            encoder_hidden = encoder.initHidden(batch_size,num_layers_enc)\n\n            input_variable = Variable(batch_x.transpose(0, 1))\n            target_variable = Variable(batch_y.transpose(0, 1))\n            \n            if configuration[\"cell_type\"] == \"LSTM\":\n                encoder_cell_state = encoder.initHidden(batch_size,num_layers_enc)\n                encoder_hidden = (encoder_hidden, encoder_cell_state)\n\n            input_length = input_variable.size()[0]\n            target_length = target_variable.size()[0]\n\n            output = torch.LongTensor(target_length, batch_size)\n\n            encoder_outputs = Variable(torch.zeros(max_length, batch_size, encoder.hidden_size))\n            encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n            \n            for ei in range(input_length):\n                encoder_output, encoder_hidden = encoder(input_variable[ei], batch_size, encoder_hidden)\n\n            decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size))\n            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n\n            decoder_hidden = encoder_hidden\n\n            for di in range(target_length):\n                decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, batch_size, decoder_hidden,encoder_outputs.reshape(batch_size,max_length, encoder.hidden_size))\n                topv, topi = decoder_output.data.topk(1)\n                decoder_input = torch.cat(tuple(topi))\n                output[di] = torch.cat(tuple(topi))\n\n            output = output.transpose(0,1)\n            for di in range(output.size()[0]):\n                ignore = [SOS_token, EOS_token, PAD_token]\n                sent = [configuration['output_lang'].index2char[letter.item()] for letter in output[di] if letter not in ignore]\n                y = [configuration['output_lang'].index2char[letter.item()] for letter in batch_y[di] if letter not in ignore]\n                if sent == y:\n                    correct += 1\n                total += 1\n\n    return (correct/total)*100\n\ndef cal_val_loss_with_attn(encoder, decoder, input_tensor, target_tensor, configuration, criterion , max_length):\n\n    with torch.no_grad():\n\n        batch_size = configuration['batch_size']\n\n        num_layers_enc = configuration['num_layers_encoder']\n        encoder_hidden = encoder.initHidden(batch_size,num_layers_enc)\n\n        input_tensor = Variable(input_tensor.transpose(0, 1))\n        target_tensor = Variable(target_tensor.transpose(0, 1))\n            \n        if configuration[\"cell_type\"] == \"LSTM\":\n            encoder_cell_state = encoder.initHidden(batch_size,num_layers_enc)\n            encoder_hidden = (encoder_hidden, encoder_cell_state)\n\n        input_length = input_tensor.size()[0]\n        target_length = target_tensor.size()[0]\n\n        encoder_outputs = Variable(torch.zeros(max_length, batch_size, encoder.hidden_size))\n        encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n\n        loss = 0\n            \n        for ei in range(input_length):\n            encoder_output, encoder_hidden = encoder(input_tensor[ei], batch_size, encoder_hidden)\n\n        decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size))\n        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n\n        decoder_hidden = encoder_hidden\n\n        for di in range(target_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, batch_size, decoder_hidden, encoder_outputs.reshape(batch_size,max_length, encoder.hidden_size))\n            topv, topi = decoder_output.data.topk(1)\n            decoder_input = torch.cat(tuple(topi))\n\n            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n            loss += criterion(decoder_output, target_tensor[di])\n\n    return loss.item() / target_length\n\ndef trainIters(encoder, decoder, train_loader, val_loader, test_loader, learning_rate, configuration, wandb_flag):\n\n    max_length = configuration['max_length_word']\n\n    train_loss_list, val_loss_list, train_acc_list, val_acc_list = [],[],[],[]\n\n    encoder_optimizer, decoder_optimizer = None, None\n\n    if configuration['optimizer']=='nadam':\n        encoder_optimizer = optim.NAdam(encoder.parameters(),lr=learning_rate)\n        decoder_optimizer = optim.NAdam(decoder.parameters(),lr=learning_rate)\n    else:\n        encoder_optimizer = optim.Adam(encoder.parameters(),lr=learning_rate)\n        decoder_optimizer = optim.Adam(decoder.parameters(),lr=learning_rate)\n\n    criterion = nn.NLLLoss()\n    \n    ep = configuration['epochs']\n\n    for i in range(ep):\n        \n        if i % 5 == 0:\n            now = datetime.now()\n            current_time = now.strftime(\"%H:%M:%S\")\n            print(\"Current Time = \", current_time)\n\n        train_loss_total = 0\n        val_loss_total = 0\n\n        for batchx, batchy in train_loader:\n            loss = None\n\n            if configuration['attention'] == False:\n                loss = train(batchx, batchy, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, configuration, max_length)\n            else:\n                loss = train_with_attn(batchx, batchy, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, configuration, max_length + 1)\n            \n            train_loss_total += loss\n        \n        train_loss_total = train_loss_total/len(train_loader)\n        print('ep : ', i, ' | ', end='')\n        print('train loss :', train_loss_total, ' | ', end='')\n\n        for batchx, batchy in val_loader:\n            loss = None\n\n            if configuration['attention'] == False:\n                loss = cal_val_loss(encoder, decoder, batchx, batchy, configuration, criterion , max_length)\n            else:\n                loss = cal_val_loss_with_attn(encoder, decoder, batchx, batchy, configuration, criterion , max_length+1)\n            \n            val_loss_total += loss\n\n        val_loss_total = val_loss_total/len(val_loader)\n\n        # train_acc = 0\n        val_acc = 0\n        \n        # if configuration['attention'] == False:\n        #     train_acc = evaluate(encoder, decoder, train_loader, configuration, criterion, max_length)\n        # else:\n        #     train_acc = evaluate_with_attn(encoder, decoder, train_loader, configuration, criterion, max_length+1)\n\n        if configuration['attention'] == False:\n            val_acc = evaluate(encoder, decoder, val_loader, configuration, criterion, max_length)\n        else:\n            val_acc = evaluate_with_attn(encoder, decoder, val_loader, configuration, criterion, max_length+1)\n        \n        # print(\"train accuracy : \" ,train_acc, ' | ', end='')\n        print('val loss :', val_loss_total, ' | ', end='')\n        print(\"val accuracy : \" ,val_acc)\n\n        if wandb_flag == True:\n            wandb.log({\n                \"train_loss\"           : train_loss_total,\n                \"validation_loss\"      : val_loss_total,\n                # \"train_accuracy\"       : train_acc,\n                \"validation_accuracy\"  : val_acc\n                })\n\n    # temp = configuration['batch_size']\n    # configuration['batch_size'] = 1\n    # if configuration['attention'] == False:\n    #     print(\"test accuracy for the model : \" ,evaluate(encoder, decoder, test_loader, configuration, criterion, max_length))\n    # else:\n    #     print(\"test accuracy for the model : \" ,evaluate_with_attn(encoder, decoder, test_loader, configuration, criterion, max_length+1))\n    # configuration['batch_size'] = temp\n\n\ndef main(config = None):\n\n    with wandb.init(config = config, entity = entity_name_ap) as run:\n        \n        config = wandb.config\n        run.name = 'hs_'+str(config.hidden_size)+'_bs_'+str(config.batch_size)+'_ct_'+config.cell_type+'_es_'+str(config.embedding_size)+'_do_'+str(config.drop_out)+'_nle_'+str(config.num_layers_en)+'_nld_'+str(config.num_layers_dec)+'_lr_'+str(config.learning_rate)+'_bd_'+str(config.bidirectional)\n\n        configuration = {\n\n                'hidden_size'         : config.hidden_size,\n                'source_lang'         : input_lang_ap,\n                'target_lang'         : target_lang_ap,\n                'cell_type'           : config.cell_type,\n                'num_layers_encoder'  : config.num_layers_en,\n                'num_layers_decoder'  : config.num_layers_en,\n                'drop_out'            : config.drop_out, \n                'embedding_size'      : config.embedding_size,\n                'bi_directional'      : bidirectional_ap,\n                'batch_size'          : config.batch_size,\n                'attention'           : attention_ap,\n                'epochs'              : config.epochs,\n                'optimizer'           : config.optimizer\n\n                # 'hidden_size'         : hidden_size_ap,\n                # 'source_lang'         : input_lang_ap,\n                # 'target_lang'         : target_lang_ap,\n                # 'cell_type'           : cell_type_ap,\n                # 'num_layers_encoder'  : num_layers_en_ap,\n                # 'num_layers_decoder'  : num_layers_dec_ap,\n                # 'drop_out'            : drop_out_ap, \n                # 'embedding_size'      : embedding_size_ap,\n                # 'bi_directional'      : bidirectional_ap,\n                # 'batch_size'          : batch_size_ap,\n                # 'attention'           : attention_ap\n            }\n        \n        \n        train_path = os.path.join(dir, configuration['target_lang'], configuration['target_lang'] + '_train.csv')\n        validation_path = os.path.join(dir, configuration['target_lang'], configuration['target_lang'] + '_valid.csv')\n        test_path = os.path.join(dir, configuration['target_lang'], configuration['target_lang'] + '_test.csv')\n\n        train_prepared_data= prepareData(train_path,configuration['source_lang'], configuration['target_lang'])\n\n        input_lang = train_prepared_data['input_lang']\n        output_lang = train_prepared_data['output_lang']\n        pairs = train_prepared_data['pairs']\n        max_input_length = train_prepared_data['max_input_length']\n        max_target_length = train_prepared_data['max_target_length']\n        \n        val_prepared_data= prepareData(validation_path,configuration['source_lang'], configuration['target_lang'])\n\n        val_pairs = val_prepared_data['pairs']\n        max_input_length_val = val_prepared_data['max_input_length']\n        max_target_length_val = val_prepared_data['max_target_length']\n\n        test_prepared_data= prepareData(validation_path, configuration['source_lang'], configuration['target_lang'])\n\n        test_pairs = test_prepared_data['pairs']\n        max_input_length_test = test_prepared_data['max_input_length']\n        max_target_length_test = test_prepared_data['max_target_length']\n\n        max_list = [max_input_length, max_target_length, max_input_length_val, max_target_length_val, max_input_length_test, max_target_length_test]\n        max_len_all = max(max_list)\n\n        max_len = max(max_input_length, max_target_length) + 2\n\n        configuration['input_lang'] = input_lang\n        configuration['output_lang'] = output_lang\n        configuration['max_length_word'] = max_len_all + 1\n\n        print(configuration['max_length_word'])\n\n        encoder1 = EncoderRNN(input_lang.n_chars, configuration)\n        decoder1 = DecoderRNN(configuration, output_lang.n_chars)\n        attndecoder1 = DecoderAttention(configuration, output_lang.n_chars)\n        if use_cuda:\n            encoder1=encoder1.cuda()\n            decoder1=decoder1.cuda()\n            attndecoder1 = attndecoder1.cuda()\n\n        pairs = variablesFromPairs(configuration['input_lang'], configuration['output_lang'], pairs , configuration['max_length_word'])\n        val_pairs = variablesFromPairs(configuration['input_lang'], configuration['output_lang'], val_pairs, configuration['max_length_word'])\n        test_pairs = variablesFromPairs(configuration['input_lang'], configuration['output_lang'], test_pairs, configuration['max_length_word'])\n\n        train_loader = torch.utils.data.DataLoader(pairs, batch_size=configuration['batch_size'], shuffle=True)\n        val_loader = torch.utils.data.DataLoader(val_pairs, batch_size=configuration['batch_size'], shuffle=True)\n        test_loader = torch.utils.data.DataLoader(test_pairs, batch_size=1, shuffle=True)\n\n        if configuration['attention'] == False :\n            trainIters(encoder1, decoder1, train_loader, val_loader, test_loader, config.learning_rate, configuration,True)\n        else : \n            trainIters(encoder1, attndecoder1, train_loader, val_loader, test_loader, config.learning_rate, configuration,True)\n\n# main()\nwandb.agent(sweep_id, main, count = 10)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":7.284247,"end_time":"2023-05-05T08:04:33.985871","exception":true,"start_time":"2023-05-05T08:04:26.701624","status":"failed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-17T08:10:03.368043Z","iopub.execute_input":"2024-05-17T08:10:03.368450Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Create sweep with ID: bkiq3ufb\nSweep URL: https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb\nbkiq3ufb\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s5j7kqvs with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamruddhipatil2526\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_081011-s5j7kqvs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/s5j7kqvs' target=\"_blank\">faithful-sweep-1</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/s5j7kqvs' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/s5j7kqvs</a>"},"metadata":{}},{"name":"stdout","text":"25\nCurrent Time =  08:10:36\nep :  0  | train loss : 1.1821789081573477  | val loss : 0.9744023311138154  | val accuracy :  0.0244140625\nep :  1  | train loss : 0.8786732283115377  | val loss : 0.6689877718687057  | val accuracy :  2.001953125\nep :  2  | train loss : 0.6334296529293062  | val loss : 0.538002740740776  | val accuracy :  10.302734375\nep :  3  | train loss : 0.5260157146692285  | val loss : 0.4738015508651734  | val accuracy :  14.5263671875\nep :  4  | train loss : 0.4716657031774518  | val loss : 0.4373766297101975  | val accuracy :  15.380859375\nCurrent Time =  08:16:24\nep :  5  | train loss : 0.43158332815170264  | val loss : 0.4312347227334976  | val accuracy :  17.7490234375\nep :  6  | train loss : 0.4126716122627264  | val loss : 0.4131257092952728  | val accuracy :  19.1162109375\nep :  7  | train loss : 0.39634008834362044  | val loss : 0.4049714350700379  | val accuracy :  22.5830078125\nep :  8  | train loss : 0.3818129067659373  | val loss : 0.40082434535026545  | val accuracy :  22.900390625\nep :  9  | train loss : 0.3603477893829347  | val loss : 0.38004350394010533  | val accuracy :  23.92578125\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.018 MB uploaded\\r'), FloatProgress(value=0.071957726778221, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▂▄▅▅▆▇███</td></tr><tr><td>validation_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.36035</td></tr><tr><td>validation_accuracy</td><td>23.92578</td></tr><tr><td>validation_loss</td><td>0.38004</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">faithful-sweep-1</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/s5j7kqvs' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/s5j7kqvs</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_081011-s5j7kqvs/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8eu8kqbc with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_082219-8eu8kqbc</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/8eu8kqbc' target=\"_blank\">hearty-sweep-2</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/8eu8kqbc' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/8eu8kqbc</a>"},"metadata":{}},{"name":"stdout","text":"25\nCurrent Time =  08:22:41\nep :  0  | train loss : 1.2265255656719212  | val loss : 1.1431159096956254  | val accuracy :  0.0\nep :  1  | train loss : 1.158942652702328  | val loss : 1.150151646733284  | val accuracy :  0.0\nep :  2  | train loss : 1.1384064003944387  | val loss : 1.1560957956314095  | val accuracy :  0.0\nep :  3  | train loss : 1.1353745723724362  | val loss : 1.1586644893884657  | val accuracy :  0.0\nep :  4  | train loss : 1.1332801050662986  | val loss : 1.1343235826492306  | val accuracy :  0.0\nCurrent Time =  08:32:58\nep :  5  | train loss : 1.100313609695434  | val loss : 1.1320157760381702  | val accuracy :  0.0\nep :  6  | train loss : 1.0936042958736427  | val loss : 1.1195667403936387  | val accuracy :  0.0\nep :  7  | train loss : 1.0920744069099415  | val loss : 1.11396703183651  | val accuracy :  0.0\nep :  8  | train loss : 1.0863276400089275  | val loss : 1.1343067520856862  | val accuracy :  0.0\nep :  9  | train loss : 1.0886933415412925  | val loss : 1.1398910313844677  | val accuracy :  0.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▅▄▃▃▂▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>▆▇██▄▄▂▁▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>1.08869</td></tr><tr><td>validation_accuracy</td><td>0.0</td></tr><tr><td>validation_loss</td><td>1.13989</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">hearty-sweep-2</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/8eu8kqbc' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/8eu8kqbc</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_082219-8eu8kqbc/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g0kms87s with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_084334-g0kms87s</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/g0kms87s' target=\"_blank\">noble-sweep-3</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/g0kms87s' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/g0kms87s</a>"},"metadata":{}},{"name":"stdout","text":"25\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"name":"stdout","text":"Current Time =  08:43:57\nep :  0  | train loss : 1.034094478225709  | val loss : 0.7345178151130676  | val accuracy :  0.732421875\nep :  1  | train loss : 0.7475876699447639  | val loss : 0.671714334487915  | val accuracy :  2.4169921875\nep :  2  | train loss : 0.688036599349976  | val loss : 0.6396774959564209  | val accuracy :  4.2724609375\nep :  3  | train loss : 0.7807015529632559  | val loss : 0.7896626305580141  | val accuracy :  1.416015625\nep :  4  | train loss : 0.7209859344482419  | val loss : 0.6838364577293395  | val accuracy :  2.392578125\nCurrent Time =  08:47:02\nep :  5  | train loss : 0.6595841044425964  | val loss : 0.6689090692996978  | val accuracy :  4.8095703125\nep :  6  | train loss : 0.6569266111373894  | val loss : 0.6346781194210054  | val accuracy :  5.9814453125\nep :  7  | train loss : 0.6389197164535528  | val loss : 0.5967388415336609  | val accuracy :  5.95703125\nep :  8  | train loss : 0.6224563133239746  | val loss : 0.5885811543464662  | val accuracy :  7.666015625\nep :  9  | train loss : 0.6052020698547362  | val loss : 0.5883350646495817  | val accuracy :  7.421875\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.019 MB uploaded\\r'), FloatProgress(value=0.0698692152917505, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▃▂▄▃▂▂▂▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▃▅▂▃▅▆▆██</td></tr><tr><td>validation_loss</td><td>▆▄▃█▄▄▃▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.6052</td></tr><tr><td>validation_accuracy</td><td>7.42188</td></tr><tr><td>validation_loss</td><td>0.58834</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">noble-sweep-3</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/g0kms87s' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/g0kms87s</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_084334-g0kms87s/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v3qw79ik with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_085021-v3qw79ik</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/v3qw79ik' target=\"_blank\">sunny-sweep-4</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/v3qw79ik' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/v3qw79ik</a>"},"metadata":{}},{"name":"stdout","text":"25\nCurrent Time =  08:50:43\nep :  0  | train loss : 1.2828766336441029  | val loss : 1.0029260516166687  | val accuracy :  0.0244140625\nep :  1  | train loss : 1.0267693305969237  | val loss : 0.9102664375305176  | val accuracy :  0.0732421875\nep :  2  | train loss : 0.8901319818496697  | val loss : 0.7740402007102967  | val accuracy :  0.3173828125\nep :  3  | train loss : 0.7709738155364991  | val loss : 0.6761842393875123  | val accuracy :  1.7333984375\nep :  4  | train loss : 0.6911198115348818  | val loss : 0.5906488144397735  | val accuracy :  4.3212890625\nCurrent Time =  08:53:44\nep :  5  | train loss : 0.6173485788345335  | val loss : 0.5459910261631012  | val accuracy :  7.32421875\nep :  6  | train loss : 0.5732883608818058  | val loss : 0.525809485912323  | val accuracy :  11.03515625\nep :  7  | train loss : 0.5292208918571472  | val loss : 0.49671299457550044  | val accuracy :  13.7451171875\nep :  8  | train loss : 0.49315358815193217  | val loss : 0.4878722929954529  | val accuracy :  15.72265625\nep :  9  | train loss : 0.4838220046997071  | val loss : 0.4582955825328827  | val accuracy :  16.0888671875\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▆▅▄▃▂▂▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▂▃▄▆▇██</td></tr><tr><td>validation_loss</td><td>█▇▅▄▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.48382</td></tr><tr><td>validation_accuracy</td><td>16.08887</td></tr><tr><td>validation_loss</td><td>0.4583</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">sunny-sweep-4</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/v3qw79ik' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/v3qw79ik</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_085021-v3qw79ik/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bv6w87in with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_085654-bv6w87in</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/bv6w87in' target=\"_blank\">blooming-sweep-5</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/bv6w87in' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/bv6w87in</a>"},"metadata":{}},{"name":"stdout","text":"25\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"name":"stdout","text":"Current Time =  08:57:17\nep :  0  | train loss : 1.7255497188568125  | val loss : 1.5194866335392  | val accuracy :  0.0\nep :  1  | train loss : 1.7913388085842137  | val loss : 1.6324345660209656  | val accuracy :  0.0\nep :  2  | train loss : 1.7639102587699909  | val loss : 3.223551950454713  | val accuracy :  0.0\nep :  3  | train loss : 1.7389682091712984  | val loss : 1.7758810472488413  | val accuracy :  0.0\nep :  4  | train loss : 1.7397629604816414  | val loss : 3.4842613530158983  | val accuracy :  0.0\nCurrent Time =  09:06:28\nep :  5  | train loss : 1.7660540236473075  | val loss : 2.1181939589977268  | val accuracy :  0.0\nep :  6  | train loss : 1.7417543045520776  | val loss : 1.702527289390564  | val accuracy :  0.0\nep :  7  | train loss : 1.7523507610321034  | val loss : 1.6600700473785404  | val accuracy :  0.0\nep :  8  | train loss : 1.7483070913314762  | val loss : 1.5858290433883668  | val accuracy :  0.0\nep :  9  | train loss : 1.739706730747221  | val loss : 1.6981233012676242  | val accuracy :  0.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>▁█▅▂▃▅▃▄▃▃</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>▁▁▇▂█▃▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>1.73971</td></tr><tr><td>validation_accuracy</td><td>0.0</td></tr><tr><td>validation_loss</td><td>1.69812</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">blooming-sweep-5</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/bv6w87in' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/bv6w87in</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_085654-bv6w87in/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2we6r9x9 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_091550-2we6r9x9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/2we6r9x9' target=\"_blank\">breezy-sweep-6</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/2we6r9x9' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/2we6r9x9</a>"},"metadata":{}},{"name":"stdout","text":"25\nCurrent Time =  09:16:12\nep :  0  | train loss : 1.2576954822540294  | val loss : 1.1547657585144044  | val accuracy :  0.0\nep :  1  | train loss : 1.1691121054649352  | val loss : 1.1932524049282076  | val accuracy :  0.0\nep :  2  | train loss : 1.1423461626052847  | val loss : 1.1840841436386111  | val accuracy :  0.0\nep :  3  | train loss : 1.13100264968872  | val loss : 1.1226990497112277  | val accuracy :  0.0\nep :  4  | train loss : 1.1137528602600089  | val loss : 1.1486127960681913  | val accuracy :  0.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▄▂▂▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>▄█▇▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>1.11375</td></tr><tr><td>validation_accuracy</td><td>0.0</td></tr><tr><td>validation_loss</td><td>1.14861</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">breezy-sweep-6</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/2we6r9x9' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/2we6r9x9</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_091550-2we6r9x9/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y9odraq9 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_092219-y9odraq9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/y9odraq9' target=\"_blank\">fiery-sweep-7</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/y9odraq9' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/y9odraq9</a>"},"metadata":{}},{"name":"stdout","text":"25\nCurrent Time =  09:22:42\nep :  0  | train loss : 1.4024961695671059  | val loss : 1.3658154815435406  | val accuracy :  0.0\nep :  1  | train loss : 1.6655961252212523  | val loss : 1.3951857888698582  | val accuracy :  0.0\nep :  2  | train loss : 1.6751100346565246  | val loss : 1.5011116635799402  | val accuracy :  0.048828125\nep :  3  | train loss : 1.7032296655654928  | val loss : 1.4566956746578217  | val accuracy :  0.048828125\nep :  4  | train loss : 1.6997152051925617  | val loss : 1.4780125784873972  | val accuracy :  0.048828125\nCurrent Time =  09:34:00\nep :  5  | train loss : 1.6986444272041348  | val loss : 1.5039650487899778  | val accuracy :  0.0\nep :  6  | train loss : 1.709139391422269  | val loss : 1.4726124697923662  | val accuracy :  0.0\nep :  7  | train loss : 1.7029914157867443  | val loss : 1.5033780634403222  | val accuracy :  0.0\nep :  8  | train loss : 1.7012083246231087  | val loss : 1.5026141774654387  | val accuracy :  0.0\nep :  9  | train loss : 1.7033204993247981  | val loss : 1.4656403928995125  | val accuracy :  0.048828125\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>▁▇▇███████</td></tr><tr><td>validation_accuracy</td><td>▁▁███▁▁▁▁█</td></tr><tr><td>validation_loss</td><td>▁▂█▆▇█▆██▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>1.70332</td></tr><tr><td>validation_accuracy</td><td>0.04883</td></tr><tr><td>validation_loss</td><td>1.46564</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fiery-sweep-7</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/y9odraq9' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/y9odraq9</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_092219-y9odraq9/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j3et5ja7 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_094531-j3et5ja7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/j3et5ja7' target=\"_blank\">divine-sweep-8</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/j3et5ja7' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/j3et5ja7</a>"},"metadata":{}},{"name":"stdout","text":"25\nCurrent Time =  09:45:54\nep :  0  | train loss : 0.877634793853761  | val loss : 0.6848592925071717  | val accuracy :  1.5380859375\nep :  1  | train loss : 0.686649202442169  | val loss : 0.6231478953361512  | val accuracy :  4.8583984375\nep :  2  | train loss : 0.658397208929062  | val loss : 0.6096479570865632  | val accuracy :  5.6396484375\nep :  3  | train loss : 0.6566326152324664  | val loss : 0.587642247080803  | val accuracy :  5.2734375\nep :  4  | train loss : 0.6318361799240111  | val loss : 0.5877847999334336  | val accuracy :  4.78515625\nCurrent Time =  09:51:28\nep :  5  | train loss : 0.6222260604858397  | val loss : 0.5847256541252135  | val accuracy :  7.6416015625\nep :  6  | train loss : 0.6353045210838315  | val loss : 0.5899566870927813  | val accuracy :  4.58984375\nep :  7  | train loss : 0.6342987348556517  | val loss : 0.5974541026353838  | val accuracy :  6.2744140625\nep :  8  | train loss : 0.6306192460536958  | val loss : 0.6079938358068466  | val accuracy :  5.908203125\nep :  9  | train loss : 0.6322963138103485  | val loss : 0.5977121192216874  | val accuracy :  6.640625\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.019 MB uploaded\\r'), FloatProgress(value=0.0709723570589137, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▅▆▅▅█▄▆▆▇</td></tr><tr><td>validation_loss</td><td>█▄▃▁▁▁▁▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.6323</td></tr><tr><td>validation_accuracy</td><td>6.64062</td></tr><tr><td>validation_loss</td><td>0.59771</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">divine-sweep-8</strong> at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/j3et5ja7' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/j3et5ja7</a><br/> View project at: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_094531-j3et5ja7/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: twen9d0r with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers_en: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_095718-twen9d0r</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/twen9d0r' target=\"_blank\">hearty-sweep-9</a></strong> to <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/sweeps/bkiq3ufb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/twen9d0r' target=\"_blank\">https://wandb.ai/samruddhipatil2526/Assifnment_3_att/runs/twen9d0r</a>"},"metadata":{}},{"name":"stdout","text":"25\nCurrent Time =  09:57:40\nep :  0  | train loss : 0.890531234836578  | val loss : 0.6579412218928337  | val accuracy :  3.0029296875\nep :  1  | train loss : 0.6989523531913758  | val loss : 0.6505891025066373  | val accuracy :  2.9541015625\n","output_type":"stream"}]}]}